{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jianx/search-exposure/')\n",
    "from train import train\n",
    "from load_data import load\n",
    "from gpu_allocator import select_device\n",
    "from gpu_allocator import cleanup_gpu_list\n",
    "import torch\n",
    "import csv\n",
    "from test import test\n",
    "from test import test_loader\n",
    "from test import get_ndcg_precision_rr\n",
    "import random\n",
    "from train import generate_sparse\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of epochs: 2\n",
      "Epoch size: 2\n",
      "Batch size: 10\n",
      "Learning rate: 0.01\n",
      "Embedding size: 64\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "epoch_size = 2\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "embed_size = 64\n",
    "\n",
    "print(\"Num of epochs:\", num_epochs)\n",
    "print(\"Epoch size:\", epoch_size)\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "print(\"Embedding size:\", embed_size)\n",
    "rank = 10\n",
    "test_batch =43\n",
    "MODEL_PATH = \"/home/jianx/data/results/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Data successfully loaded.\n",
      "Positive Negative Pair dict size: 400782\n",
      "Num of queries: 808731\n",
      "Num of passages: 8841823\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data\")\n",
    "pos_neg_dict, query_dict, passage_dict, top_dict, rating_dict, query_test_dict = load()\n",
    "print(\"Data successfully loaded.\")\n",
    "print(\"Positive Negative Pair dict size: \" + str(len(pos_neg_dict)))\n",
    "print(\"Num of queries: \" + str(len(query_dict)))\n",
    "print(\"Num of passages: \" + str(len(passage_dict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_HIDDEN_NODES = 64\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "DROPOUT_RATE = 0.1\n",
    "FEAT_COUNT = 100000\n",
    "\n",
    "\n",
    "# Define the network\n",
    "class DSSM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, device):\n",
    "        super(DSSM, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        last_dim = FEAT_COUNT\n",
    "        for i in range(NUM_HIDDEN_LAYERS):\n",
    "            layers.append(nn.Linear(last_dim, NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.LayerNorm(NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.Dropout(p=DROPOUT_RATE))\n",
    "            last_dim = NUM_HIDDEN_NODES\n",
    "        layers.append(nn.Linear(last_dim, embed_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.scale = torch.tensor([10], dtype=torch.float).to(device)\n",
    "    def forward(self, x):\n",
    "        embedding = nn.EmbeddingBag(FEAT_COUNT, FEAT_COUNT)\n",
    "        x = embedding(x).sum(0)\n",
    "        return self.model(x) * self.scale\n",
    "\n",
    "    def parameter_count(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "VOCAB_LEN = 100000\n",
    "\n",
    "\n",
    "def sparse_to_dense(idx, vocab_len=VOCAB_LEN):\n",
    "    index_tensor = torch.LongTensor([idx])\n",
    "    value_tensor = torch.Tensor([1] * len(idx))\n",
    "    dense_tensor = torch.sparse.FloatTensor(index_tensor, value_tensor, torch.Size([vocab_len, ])).to_dense()\n",
    "    return dense_tensor\n",
    "\n",
    "\n",
    "def generate_sparse(idx, vocab_len=VOCAB_LEN):\n",
    "    index_tensor = torch.LongTensor([idx])\n",
    "    value_tensor = torch.Tensor([1] * len(idx))\n",
    "    sparse_tensor = torch.sparse.FloatTensor(index_tensor, value_tensor, torch.Size([vocab_len, ]))\n",
    "    return sparse_tensor\n",
    "\n",
    "\n",
    "def mini_batch(batch_size, device, pos_neg_dict, query_dict, passage_dict):\n",
    "    query_list = list(pos_neg_dict.keys())\n",
    "    queries = []\n",
    "    pos = []\n",
    "    neg = []\n",
    "    while len(queries) < batch_size:\n",
    "        qid = random.sample(query_list, 1)[0]\n",
    "        pos_neg_pair = random.sample(pos_neg_dict[qid], 1)\n",
    "        pos_pid = pos_neg_pair[0][0]\n",
    "        neg_pid = pos_neg_pair[0][1]\n",
    "        q_seq = query_dict[qid]\n",
    "        pos_seq = passage_dict[pos_pid]\n",
    "        neg_seq = passage_dict[neg_pid]\n",
    "        if q_seq != [] and pos_seq != [] and neg_seq != []:\n",
    "            queries.append(torch.LongTensor(q_seq).to(device))\n",
    "            pos.append(torch.LongTensor(pos_seq).to(device))\n",
    "            neg.append(torch.LongTensor(neg_seq).to(device))\n",
    "    labels = [0 for i in range(batch_size)]\n",
    "    return queries, pos, neg, labels\n",
    "\n",
    "\n",
    "def train(net, epoch_size, batch_size, optimizer, device, pos_neg_dict, query_dict,\n",
    "          passage_dict):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for mb_idx in range(epoch_size):\n",
    "        # Read in a new mini-batch of data!\n",
    "        queries, pos, neg, labels = mini_batch(batch_size, device, pos_neg_dict, query_dict,\n",
    "                                               passage_dict)\n",
    "        optimizer.zero_grad()\n",
    "        q_embed = net(queries)\n",
    "        pos_embed = net(pos)\n",
    "        neg_embed = net(neg)\n",
    "        out_pos = torch.cosine_similarity(q_embed, pos_embed).unsqueeze(0).T\n",
    "        out_neg = torch.cosine_similarity(q_embed, neg_embed).unsqueeze(0).T\n",
    "        out = torch.cat((out_pos, out_neg), -1)\n",
    "        loss = criterion(out, torch.tensor(labels).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # print(str(mb_idx) + \" iteration: \" + str(train_loss / (mb_idx + 1)))\n",
    "    return train_loss / epoch_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CURRENT_DEVICE = torch.device(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "net = DSSM(embed_size=embed_size, device=CURRENT_DEVICE).to(CURRENT_DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-2f3c02176fa4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlearning_rate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     train_loss = train(net, epoch_size, batch_size, optimizer, CURRENT_DEVICE, pos_neg_dict,\n\u001B[0;32m----> 4\u001B[0;31m                        query_dict, passage_dict)\n\u001B[0m\u001B[1;32m      5\u001B[0m     avg_ndcg, avg_prec, avg_rr = test(net, CURRENT_DEVICE, test_batch, top_dict, query_test_dict, passage_dict,\n\u001B[1;32m      6\u001B[0m                                       rating_dict, rank)\n",
      "\u001B[0;32m<ipython-input-23-256b40fac629>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(net, epoch_size, batch_size, optimizer, device, pos_neg_dict, query_dict, passage_dict)\u001B[0m\n\u001B[1;32m     52\u001B[0m                                                passage_dict)\n\u001B[1;32m     53\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mq_embed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mqueries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mpos_embed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpos\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mneg_embed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mneg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-12-cc0e8f458da6>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscale\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscale\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mparameter_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 100\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    101\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1606\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mTensor\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtens_ops\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhas_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtens_ops\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1607\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtens_ops\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1608\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1609\u001B[0m         \u001B[0;31m# fused op is marginally faster\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1610\u001B[0m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "for ep_idx in range(num_epochs):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    train_loss = train(net, epoch_size, batch_size, optimizer, CURRENT_DEVICE, pos_neg_dict,\n",
    "                       query_dict, passage_dict)\n",
    "    avg_ndcg, avg_prec, avg_rr = test(net, CURRENT_DEVICE, test_batch, top_dict, query_test_dict, passage_dict,\n",
    "                                      rating_dict, rank)\n",
    "    print(\"Epoch:{}, loss:{}, NDCG:{}, P:{}, RR:{}\".format(ep_idx, train_loss, avg_ndcg, avg_prec, avg_rr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-3.6896, -0.3273, -2.5080,  0.5653, -1.2815,  1.3265, -0.1262,  0.8897,\n          0.5738,  0.3181],\n        [-0.4931, -0.1923, -0.8758,  0.5458, -3.1003, -0.6314,  0.2613,  0.9411,\n         -0.7424, -2.6701]], grad_fn=<EmbeddingBagBackward>)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.EmbeddingBag(10, 10, mode=\"sum\", )\n",
    "input = torch.LongTensor([[1,2,4,5], [0,1,9,8]])\n",
    "embedding(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2] at entry 0 and [4] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-0c3f614da086>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLongTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLongTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m9\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: stack expects each tensor to be equal size, but got [2] at entry 0 and [4] at entry 1"
     ]
    }
   ],
   "source": [
    "tt = [torch.LongTensor([1,2]), torch.LongTensor([1,2,9,8])]\n",
    "torch.stack(tt, dim = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "CURRENT_DEVICE = torch.device(\"cuda:3\")\n",
    "loaded_net = torch.load(\"/home/jianx/data/results/300_1500_100_0.01_256.model\").to(CURRENT_DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1056992, 0.9988421201705933), (742037, 0.9946508407592773), (2815189, 0.9936875700950623), (4945929, 0.9884414672851562), (2140502, 0.9838024377822876), (5245312, 0.977665901184082), (1768732, 0.9721917510032654), (5825120, 0.972136914730072), (3695908, 0.9699577689170837), (6148227, 0.9699546098709106), (4576122, 0.9673935174942017), (2617198, 0.966935396194458), (2244145, 0.9666087031364441), (3261114, 0.9616740942001343), (691288, 0.9606649875640869), (4016930, 0.955830991268158), (5072800, 0.9537691473960876), (7959720, 0.9487412571907043), (6828980, 0.9475806951522827), (4367833, 0.9419851899147034), (8105077, 0.9398841261863708), (4367830, 0.937769889831543), (3518297, 0.9308198094367981), (4422672, 0.9298780560493469), (1768733, 0.9290626645088196), (7670907, 0.928348183631897), (7857313, 0.9272759556770325), (1735869, 0.9264847040176392), (6059146, 0.9254395365715027), (5362609, 0.9252550005912781), (5486771, 0.9239426851272583), (4422671, 0.923937201499939), (995302, 0.923130214214325), (6017940, 0.9217230081558228), (5928729, 0.9185269474983215), (5996691, 0.9165483713150024), (5117486, 0.9159664511680603), (7263164, 0.915140688419342), (2769629, 0.9150047302246094), (7385222, 0.9131250977516174), (4016937, 0.9125173687934875), (6849692, 0.910686194896698), (1280572, 0.9090892672538757), (1768729, 0.908784031867981), (4149320, 0.9086231589317322), (4149319, 0.9086231589317322), (4149323, 0.9086231589317322), (6174324, 0.9086199998855591), (4422678, 0.9080911874771118), (2595622, 0.9080777168273926), (5227589, 0.9065971970558167), (6455607, 0.9047515392303467), (28081, 0.9014734029769897), (3064603, 0.8999232053756714), (5257984, 0.8995088934898376), (5257992, 0.8995088934898376), (1577658, 0.8990150690078735), (7974450, 0.8977988958358765), (1280567, 0.8975732922554016), (6557144, 0.8949256539344788), (5825125, 0.894537091255188), (6252170, 0.894478440284729), (6438275, 0.894478440284729), (2363456, 0.894478440284729), (6238006, 0.894478440284729), (2496261, 0.8890405297279358), (7126000, 0.888973593711853), (1399077, 0.8881586790084839), (1520227, 0.8881368637084961), (5996693, 0.887875497341156), (7883487, 0.8878200650215149), (6557145, 0.8877803683280945), (7060264, 0.8864293098449707), (8777339, 0.8863236308097839), (3745699, 0.8855780363082886), (657401, 0.8784250020980835), (5938426, 0.878008246421814), (8118886, 0.8773534893989563), (8043443, 0.8765257000923157), (2204118, 0.8765045404434204), (5050468, 0.8760685920715332), (1896945, 0.8755670785903931), (6644643, 0.8712260127067566), (7567127, 0.8693814277648926), (555331, 0.8664734959602356), (2853276, 0.86445152759552), (2617205, 0.86359041929245), (5867542, 0.8605093955993652), (1633101, 0.8597962856292725), (2912120, 0.8596199154853821), (259559, 0.858348548412323), (3195579, 0.8582493662834167), (1311059, 0.856359601020813), (6696503, 0.8543150424957275), (5867547, 0.8536539077758789), (2884190, 0.8513267040252686), (2145127, 0.8495379090309143), (5867541, 0.8473601937294006), (4368292, 0.8465835452079773), (5141464, 0.8444771766662598), (8599281, 0.8444574475288391), (4422670, 0.8439931273460388), (6765125, 0.8400517106056213), (2160010, 0.8393605947494507), (6593841, 0.8388003706932068), (6864673, 0.83453369140625), (4961024, 0.8331588506698608), (1630250, 0.8331180214881897), (6720376, 0.8323678374290466), (8713116, 0.8321558237075806), (1454811, 0.8313461542129517), (742043, 0.8304264545440674), (459397, 0.8303631544113159), (7044793, 0.8275419473648071), (1397539, 0.8264126181602478), (657408, 0.8243399262428284), (5362613, 0.8224140405654907), (2431016, 0.8195369243621826), (8128794, 0.818473756313324), (1019929, 0.8172224164009094), (1768731, 0.8163917660713196), (3913221, 0.8157819509506226), (6093377, 0.8156300783157349), (5825123, 0.8131973147392273), (4521746, 0.8131255507469177), (450656, 0.8123704195022583), (5095118, 0.8093544840812683), (1199343, 0.8013541102409363), (3851632, 0.8004119992256165), (5545723, 0.7965047359466553), (4367828, 0.7952218651771545), (4751839, 0.7948636412620544), (1896939, 0.790600061416626), (7044794, 0.7893111705780029), (3089474, 0.7811399698257446), (5545722, 0.7784924507141113), (1626894, 0.7771488428115845), (1896940, 0.7758849263191223), (8118888, 0.7755067944526672), (7513064, 0.7733728885650635), (7724930, 0.7717381715774536), (5825124, 0.7686779499053955), (7377278, 0.7686068415641785), (654716, 0.7685189247131348), (4016935, 0.7677055597305298), (3957201, 0.7672117948532104), (4853977, 0.7662283778190613), (4422676, 0.7617023587226868), (4422673, 0.7596695423126221), (7263162, 0.7594265937805176), (5591644, 0.7567160129547119), (4016936, 0.7499015927314758), (4961028, 0.7483606338500977), (7885169, 0.7466287612915039), (7377270, 0.7456056475639343), (6765123, 0.7426060438156128), (6361464, 0.7411239147186279), (5188745, 0.7389780879020691), (2595623, 0.7385005354881287), (7377277, 0.7365148663520813), (933160, 0.7315133213996887), (1525430, 0.728851318359375), (1168001, 0.7268857955932617), (1167998, 0.7268857955932617), (8387587, 0.724697470664978), (1251392, 0.724697470664978), (1149495, 0.7236394882202148), (4407177, 0.7236394882202148), (4628484, 0.7219755053520203), (742044, 0.7212410569190979), (4311392, 0.7211905121803284), (7385214, 0.7200707197189331), (6455610, 0.7180582284927368), (6148219, 0.7144268155097961), (6147932, 0.7100904583930969), (7766971, 0.7096220850944519), (6597538, 0.7085253596305847), (5088106, 0.7083297371864319), (5781995, 0.7027955651283264), (1168000, 0.700404167175293), (5088110, 0.7002687454223633), (3851630, 0.7002077102661133), (4064657, 0.6983086466789246), (2082753, 0.689081072807312), (3868439, 0.6852962374687195), (5606444, 0.6836867928504944), (213006, 0.683040976524353), (3207413, 0.6817666888237), (5209702, 0.6773413419723511), (79039, 0.6750127673149109), (549548, 0.6741834878921509), (168671, 0.6732419729232788), (2617197, 0.6676017642021179), (7263165, 0.6645262241363525), (7623595, 0.6564819812774658), (4111480, 0.6551272869110107), (2092827, 0.6530750393867493), (4715377, 0.6515527367591858), (1560548, 0.6510176062583923), (807271, 0.6505573987960815), (5649864, 0.6474214792251587), (6021900, 0.6398690938949585), (8503449, 0.6370513439178467), (3436902, 0.6360216736793518), (4422675, 0.6349388360977173), (6954560, 0.6318151354789734), (1597174, 0.6249195337295532), (8145189, 0.6223043203353882), (7096044, 0.6206339001655579), (2773550, 0.6171663403511047), (5050470, 0.6153295040130615), (5996692, 0.6134909987449646), (8386762, 0.612579345703125), (2354946, 0.6109729409217834), (4367831, 0.6050074696540833), (6639652, 0.6045989990234375), (5546290, 0.6045039892196655), (3405849, 0.6035197973251343), (5188746, 0.5960660576820374), (7385219, 0.5946682095527649), (6017938, 0.5934616923332214), (8118887, 0.5920540690422058), (3028103, 0.5913520455360413), (1454809, 0.5853228569030762), (8126828, 0.5843841433525085), (3132938, 0.5794207453727722), (3357726, 0.5794207453727722), (1454808, 0.5791486501693726), (2362828, 0.5736872553825378), (213011, 0.5595541000366211), (8128793, 0.5524406433105469), (5362614, 0.5523381233215332), (2158684, 0.5479564666748047), (2528856, 0.5413291454315186), (4016934, 0.5409680604934692), (5546288, 0.5395591855049133), (8441802, 0.5341354012489319), (1280563, 0.531655490398407), (7775858, 0.5312842130661011), (4288373, 0.5302509069442749), (2710305, 0.5285443067550659), (7117102, 0.5182055234909058), (7117106, 0.5182055234909058), (4016931, 0.5163394212722778), (79043, 0.5111819505691528), (5514594, 0.4927256405353546), (631946, 0.4927256405353546), (7959713, 0.4879576861858368), (2721287, 0.4822668135166168), (5649868, 0.467730313539505), (3444950, 0.45952901244163513), (7024382, 0.45786789059638977), (2573177, 0.4538939297199249), (213008, 0.4524186849594116), (5355190, 0.4505181610584259), (8503446, 0.448741614818573), (2795793, 0.44699254631996155), (1944712, 0.4451206624507904), (3436901, 0.44380131363868713), (5938418, 0.43971386551856995), (7050819, 0.4360593557357788), (6232395, 0.4357576370239258), (1454807, 0.4315837323665619), (8126831, 0.43099966645240784), (1255877, 0.4295583665370941), (6950473, 0.4270404875278473), (6950474, 0.4270404875278473), (3946548, 0.4238976240158081), (4486954, 0.4221835732460022), (7376902, 0.4168941080570221), (4949774, 0.415818452835083), (742036, 0.41123080253601074), (6059154, 0.4096243977546692), (6486041, 0.405560165643692), (1066532, 0.39810702204704285), (7559642, 0.3916975259780884), (6466105, 0.38867759704589844), (1066537, 0.3845430910587311), (3049193, 0.38016900420188904), (2773546, 0.3795936107635498), (2773545, 0.3795936107635498), (1397831, 0.37265247106552124), (3049191, 0.3696582019329071), (5591642, 0.36390119791030884), (8503453, 0.3626142740249634), (5415590, 0.35991233587265015), (7189262, 0.35669466853141785), (6758454, 0.35407716035842896), (2911345, 0.35158759355545044), (7306673, 0.349966436624527), (3325914, 0.3473116457462311), (6174328, 0.3463064730167389), (3795842, 0.33769258856773376), (3064610, 0.3371681571006775), (6101624, 0.3323339521884918), (6166403, 0.3214057981967926), (6267538, 0.3160970211029053), (3997986, 0.3140539824962616), (7440220, 0.3115561008453369), (7011361, 0.30650657415390015), (4498864, 0.29006296396255493), (6249670, 0.28922492265701294), (2773547, 0.28577813506126404), (4604766, 0.28358685970306396), (3002629, 0.2762792408466339), (6593840, 0.27573150396347046), (7377274, 0.27565643191337585), (2341681, 0.270767480134964), (7900999, 0.26286375522613525), (3808153, 0.24800743162631989), (8627177, 0.24257101118564606), (2827217, 0.22924493253231049), (2584092, 0.2221604585647583), (3325381, 0.21915501356124878), (1485049, 0.21504056453704834), (7618558, 0.18578556180000305), (6155503, 0.18461227416992188), (1897051, 0.18254831433296204), (1768728, 0.18129751086235046), (3851627, 0.1790628433227539), (6906387, 0.17221251130104065), (4898185, 0.16976937651634216), (2864289, 0.1653614044189453), (5955948, 0.15983179211616516), (5088113, 0.1597634255886078), (2617200, 0.1595020741224289), (1922827, 0.1560654640197754), (5253279, 0.1529606729745865), (5258080, 0.1529606729745865), (4193422, 0.14645789563655853), (3851625, 0.14207236468791962), (1253484, 0.13730888068675995), (79036, 0.13525843620300293), (8705945, 0.13497495651245117), (5591647, 0.1345612108707428), (1287014, 0.13219602406024933), (213009, 0.13026724755764008), (6017944, 0.12755043804645538), (4016933, 0.12290547043085098), (6992977, 0.11951293796300888), (6593839, 0.11758416891098022), (7189263, 0.11396578699350357), (2920385, 0.1109916940331459), (1533641, 0.10947512835264206), (2181089, 0.10118980705738068), (3405850, 0.08939807116985321), (5460440, 0.0834229439496994), (58131, 0.07821938395500183), (3518298, 0.07611426711082458), (1454814, 0.07595892250537872), (8724208, 0.07516046613454819), (5279666, 0.07009190320968628), (495971, 0.06743965297937393), (2773548, 0.05618881806731224), (5871894, 0.050567060708999634), (2986372, 0.05016203597187996), (5362612, 0.04929077625274658), (6879145, 0.04696119949221611), (631945, 0.04003440961241722), (3357893, 0.033715661615133286), (3357895, 0.033715661615133286), (7670912, 0.030250342562794685), (5171761, 0.018379580229520798), (4523656, 0.017854604870080948), (6147925, 0.007404157426208258), (854787, -0.003740375628694892), (4545407, -0.005269984249025583), (3648205, -0.011034289374947548), (3837966, -0.01299660187214613), (6017945, -0.02044058032333851), (8162984, -0.028147242963314056), (893785, -0.03130670264363289), (4867779, -0.0366470031440258), (2780065, -0.037371695041656494), (7458700, -0.03759274631738663), (4367832, -0.045282166451215744), (6174325, -0.04629999399185181), (5955945, -0.05208100005984306), (5546289, -0.054941944777965546), (8045938, -0.06248911842703819), (8092785, -0.06293239444494247), (4908893, -0.07872026413679123), (4096313, -0.08147908747196198), (4854578, -0.0818188413977623), (8128796, -0.08340385556221008), (7263163, -0.08505687862634659), (5514590, -0.0890873372554779), (4628478, -0.09032422304153442), (6021902, -0.09090127795934677), (4296063, -0.09383965283632278), (6115723, -0.10403474420309067), (7497491, -0.1047249510884285), (2264197, -0.10706214606761932), (5514588, -0.11310379952192307), (6021898, -0.11504452675580978), (7125345, -0.11620160192251205), (4751833, -0.121373251080513), (6174329, -0.13085520267486572), (2573176, -0.1344723403453827), (4783291, -0.146983802318573), (2994500, -0.149495929479599), (657400, -0.15269607305526733), (4107371, -0.16353222727775574), (7868624, -0.16542664170265198), (6211905, -0.17327940464019775), (4370052, -0.17613708972930908), (1560551, -0.1802731156349182), (502883, -0.18279317021369934), (5942519, -0.184194415807724), (5938425, -0.18529465794563293), (3851628, -0.18853308260440826), (657403, -0.1972375363111496), (85200, -0.19730865955352783), (5591643, -0.1988917589187622), (6278837, -0.20032374560832977), (8729210, -0.20725134015083313), (6639655, -0.2133154422044754), (4448412, -0.2191607505083084), (3125155, -0.22621141374111176), (7890529, -0.22815820574760437), (657399, -0.23090891540050507), (742041, -0.23193421959877014), (4231258, -0.24684438109397888), (495418, -0.24841678142547607), (6267244, -0.2498878836631775), (5012201, -0.2594774067401886), (6455612, -0.2628507614135742), (694173, -0.2629680633544922), (8126832, -0.26336154341697693), (7390080, -0.26356741786003113), (8137621, -0.26373520493507385), (1007896, -0.28178995847702026), (5938421, -0.28460535407066345), (6688843, -0.28753411769866943), (7371012, -0.3010239005088806), (3200386, -0.3075200915336609), (555335, -0.31153547763824463), (7901002, -0.3241918981075287), (4561601, -0.3251623809337616), (5782000, -0.3269149363040924), (4195658, -0.328523725271225), (727439, -0.3347149193286896), (4570040, -0.3536607623100281), (8363445, -0.3536663353443146), (8041925, -0.364945650100708), (411188, -0.3788338899612427), (1077734, -0.38185274600982666), (3472571, -0.3859570324420929), (5712380, -0.39091846346855164), (1066539, -0.39731284976005554), (1655114, -0.3983624279499054), (156331, -0.4076453745365143), (4979140, -0.41009050607681274), (58130, -0.41508686542510986), (3718550, -0.4167118966579437), (3436894, -0.42022261023521423), (5269271, -0.4218865633010864), (5781999, -0.42259666323661804), (807273, -0.42417246103286743), (4561420, -0.4255225360393524), (8155335, -0.42891401052474976), (2133118, -0.42984646558761597), (2354947, -0.43059659004211426), (8729211, -0.433217316865921), (2056984, -0.4348547160625458), (7890535, -0.4526616930961609), (1801225, -0.4558270573616028), (6088772, -0.4583435356616974), (7385216, -0.4630284905433655), (6221608, -0.46359196305274963), (3026986, -0.4646682143211365), (8133335, -0.4744008183479309), (807274, -0.4752390682697296), (3422862, -0.4802282154560089), (8126837, -0.4845709800720215), (1564996, -0.48657163977622986), (7861397, -0.4867593050003052), (2092826, -0.48785245418548584), (1135139, -0.48903584480285645), (5962826, -0.49103930592536926), (1559529, -0.49430209398269653), (6029448, -0.49949413537979126), (5038049, -0.49974149465560913), (4290185, -0.5049474239349365), (507344, -0.5077922940254211), (5938419, -0.5113354325294495), (40909, -0.5129532814025879), (387309, -0.5137804746627808), (5386684, -0.5164962410926819), (3518304, -0.5223855972290039), (5965729, -0.5249274969100952), (3851624, -0.5251659154891968), (6688848, -0.5281980633735657), (7343331, -0.5314859747886658), (5959580, -0.5353517532348633), (8126830, -0.5387000441551208), (7603375, -0.5432681441307068), (4167476, -0.5599926114082336), (1317211, -0.5616166591644287), (1681785, -0.5648229718208313), (4064650, -0.5669420957565308), (8820310, -0.5760351419448853), (2453382, -0.577599287033081), (8004278, -0.5790499448776245), (3990997, -0.5800210237503052), (3696727, -0.5806041359901428), (1050651, -0.5861657857894897), (919328, -0.5912253856658936), (6257297, -0.6070218086242676), (3518300, -0.6090521216392517), (5195741, -0.6186978816986084), (5885793, -0.6187668442726135), (2354940, -0.6223559379577637), (4783289, -0.6271806359291077), (7497495, -0.6319766640663147), (3049199, -0.6341019868850708), (7440218, -0.6362881064414978), (2162939, -0.6365073323249817), (4436574, -0.6373833417892456), (4280736, -0.6379519104957581), (3607995, -0.6388651132583618), (3607994, -0.6388651132583618), (2440711, -0.6451717615127563), (7497492, -0.65211421251297), (7995039, -0.6525015830993652), (2580323, -0.6527524590492249), (7980409, -0.6573849320411682), (459403, -0.6577479839324951), (1768734, -0.6585550308227539), (2109966, -0.6585993766784668), (2110583, -0.6604452729225159), (8167405, -0.661791980266571), (1512674, -0.6675208806991577), (1593078, -0.6690419316291809), (3125150, -0.670400857925415), (807275, -0.6723308563232422), (7138132, -0.6725407838821411), (7196459, -0.6735602021217346), (1433630, -0.6803105473518372), (3049194, -0.6884874105453491), (1600752, -0.6894206404685974), (8185225, -0.6895105838775635), (1317855, -0.6899040937423706), (6431061, -0.6932730078697205), (4628485, -0.6973286271095276), (3685677, -0.6974964737892151), (1445504, -0.6991170048713684), (7974454, -0.7018378376960754), (3578994, -0.7083885073661804), (5362616, -0.7087578773498535), (970140, -0.7087719440460205), (8342232, -0.7094111442565918), (669715, -0.7151373028755188), (5546286, -0.7185098528862), (2407444, -0.7199990153312683), (8390993, -0.7207995057106018), (3518301, -0.721674919128418), (6688850, -0.7255116105079651), (7377272, -0.7264225482940674), (8128791, -0.7286794185638428), (7352537, -0.7287352681159973), (1280564, -0.7291727662086487), (5188754, -0.7313570380210876), (5548679, -0.7328272461891174), (7377275, -0.733398973941803), (6314214, -0.737551212310791), (6174327, -0.7449382543563843), (3080918, -0.7462671399116516), (5514593, -0.7467981576919556), (4714190, -0.7482134699821472), (3607996, -0.7486276626586914), (3125146, -0.7498564124107361), (2041803, -0.7514563202857971), (4290181, -0.7515554428100586), (5362611, -0.7516129612922668), (8729216, -0.7520142793655396), (3687624, -0.7586649656295776), (495975, -0.760217547416687), (2278605, -0.7640169262886047), (4107542, -0.7674087285995483), (8754443, -0.767927885055542), (3657772, -0.7685259580612183), (4313666, -0.7689056992530823), (2884957, -0.7729968428611755), (5514592, -0.7735238075256348), (4473063, -0.7749409675598145), (5591648, -0.7750711441040039), (8285580, -0.7761031985282898), (4783292, -0.7772023677825928), (219223, -0.7825581431388855), (6909119, -0.7839529514312744), (4296682, -0.7849506735801697), (8150850, -0.7876111268997192), (187827, -0.788207471370697), (2311357, -0.7892532348632812), (7277236, -0.7894726395606995), (3869118, -0.791088342666626), (2370086, -0.7911762595176697), (7901001, -0.7917159795761108), (6313569, -0.7917306423187256), (8141888, -0.7925674915313721), (1023926, -0.7936272621154785), (1280244, -0.7941681146621704), (723853, -0.7942410707473755), (2370088, -0.7943291664123535), (8737202, -0.7962551116943359), (1185848, -0.7979621291160583), (1757018, -0.7980521321296692), (2305865, -0.7989901900291443), (4290271, -0.7990269064903259), (3378169, -0.8008520603179932), (156334, -0.8028296828269958), (1415366, -0.8031429648399353), (2274155, -0.8033493161201477), (2712936, -0.803645133972168), (1299639, -0.8048484325408936), (7609974, -0.8048484325408936), (2884185, -0.8060548305511475), (3998591, -0.8077086210250854), (8043439, -0.8093870282173157), (8120648, -0.8105071187019348), (5416029, -0.8108214735984802), (4064654, -0.8131530284881592), (3125148, -0.8136285543441772), (5346399, -0.8176456093788147), (3290247, -0.817783534526825), (7522332, -0.8189478516578674), (8126833, -0.8205494284629822), (881626, -0.8234173059463501), (3485252, -0.8245636224746704), (8565156, -0.825354278087616), (4418355, -0.8263055682182312), (4216336, -0.8270977735519409), (5947764, -0.8285893797874451), (5546284, -0.8288187980651855), (5132846, -0.8297253847122192), (3125154, -0.8302027583122253), (4498871, -0.8304078578948975), (4783284, -0.8310264945030212), (8566591, -0.8315675854682922), (7890531, -0.8330481648445129), (5027227, -0.8351280689239502), (8594274, -0.8357154130935669), (8692534, -0.8367539644241333), (5815952, -0.8395349383354187), (7536939, -0.839678168296814), (8503450, -0.8402827978134155), (1805017, -0.8444692492485046), (1280570, -0.847416341304779), (3990056, -0.8474826812744141), (717410, -0.8485162258148193), (3329254, -0.8501548767089844), (4093899, -0.8517627120018005), (1768727, -0.8528333902359009), (1270353, -0.8529771566390991), (8611712, -0.8532507419586182), (2463136, -0.8534611463546753), (5081902, -0.8538888692855835), (5863434, -0.854326069355011), (4412230, -0.8553565144538879), (5574006, -0.856724202632904), (7003339, -0.8569653630256653), (4016939, -0.8581072688102722), (8446656, -0.8585895895957947), (7385221, -0.8587698340415955), (3687620, -0.8592018485069275), (4296684, -0.859237790107727), (2908717, -0.8600696325302124), (777899, -0.8611165881156921), (7901000, -0.8625320792198181), (2305871, -0.8625524044036865), (5188751, -0.8635580539703369), (555332, -0.8638399839401245), (6177158, -0.8639170527458191), (2694593, -0.8675042986869812), (213005, -0.8675404787063599), (1280571, -0.8684775233268738), (3378168, -0.8692082762718201), (8729213, -0.869736909866333), (7707094, -0.8699973821640015), (6593845, -0.8701490759849548), (4016938, -0.8702803254127502), (3643127, -0.8704427480697632), (2628419, -0.8706310391426086), (1206406, -0.8707291483879089), (7618564, -0.8707955479621887), (1023697, -0.8708780407905579), (1270360, -0.8712596893310547), (6585210, -0.8719149231910706), (2711823, -0.8720486760139465), (8729214, -0.8721106052398682), (807278, -0.8731197714805603), (4909736, -0.8731976747512817), (147652, -0.8739694356918335), (2617204, -0.8743258118629456), (2788889, -0.8746959567070007), (7510911, -0.8750022053718567), (2354941, -0.8750783801078796), (6486038, -0.8754729628562927), (222977, -0.8756787776947021), (1168002, -0.876652181148529), (4981632, -0.8770815134048462), (6992975, -0.8778822422027588), (4751832, -0.8782938122749329), (6511446, -0.8793339133262634), (1658111, -0.8804276585578918), (2862145, -0.8805249929428101), (5536332, -0.880535900592804), (5226709, -0.8808606863021851), (1896944, -0.880954384803772), (657405, -0.8810210227966309), (717407, -0.8816708922386169), (7497490, -0.8817354440689087), (5664603, -0.8828257918357849), (1655112, -0.8831489086151123), (4574232, -0.8831756114959717), (5096139, -0.8834077715873718), (1920709, -0.8837010860443115), (4498873, -0.883899450302124), (5362618, -0.8844919800758362), (3364091, -0.8853029608726501), (802366, -0.8861712217330933), (8503455, -0.8864362239837646), (6750273, -0.887181282043457), (1850851, -0.8872173428535461), (1786068, -0.8872215747833252), (6909270, -0.8874678611755371), (4186999, -0.8880242109298706), (3990061, -0.8894461393356323), (5194230, -0.8896116614341736), (7385215, -0.8899944424629211), (7988099, -0.890126645565033), (6289636, -0.8909754157066345), (213007, -0.8914157748222351), (2305870, -0.8915452361106873), (2643125, -0.8919510841369629), (5275872, -0.892027735710144), (483955, -0.8921476006507874), (7793947, -0.8926544189453125), (5346404, -0.8927749395370483), (79038, -0.8928008079528809), (555339, -0.892852783203125), (4057784, -0.8933835029602051), (457997, -0.8934021592140198), (2459609, -0.8935441970825195), (147646, -0.8937588334083557), (4783283, -0.8942041993141174), (657407, -0.8944807052612305), (436903, -0.8946148157119751), (5215408, -0.8951838612556458), (5215406, -0.8951838612556458), (8299324, -0.8954310417175293), (6788351, -0.8956431746482849), (1550774, -0.8957560062408447), (2891896, -0.8960922956466675), (4174984, -0.8963607549667358), (8714674, -0.896477222442627), (8069986, -0.8965244293212891), (6992968, -0.8965831995010376), (4751837, -0.8967901468276978), (4072066, -0.8971418142318726), (8037848, -0.8972989916801453), (2774608, -0.8975101709365845), (8128798, -0.8975656628608704), (436902, -0.8977964520454407), (596894, -0.8985506296157837), (7385213, -0.8986223340034485), (6110299, -0.8987968564033508), (5700362, -0.8992738723754883), (1441493, -0.8994383811950684), (4860928, -0.9002281427383423), (6312554, -0.9007024765014648), (1352304, -0.9007425904273987), (4190636, -0.9012678265571594), (871000, -0.9015655517578125), (313538, -0.9020218253135681), (6686640, -0.9024395942687988), (7507181, -0.9024789929389954), (5333311, -0.9029006958007812), (6284746, -0.9036509990692139), (5700369, -0.9038873910903931), (4691644, -0.9045330286026001), (3543393, -0.9046453833580017), (6215772, -0.9056784510612488), (2001934, -0.9058768153190613), (147648, -0.9064018726348877), (4961032, -0.9064489006996155), (8486210, -0.9068655967712402), (3711446, -0.9071053266525269), (313543, -0.9072240591049194), (7180572, -0.9072639346122742), (7751929, -0.9073245525360107), (5315057, -0.9073417782783508), (5735527, -0.907366156578064), (1658786, -0.9075382947921753), (79035, -0.9083347916603088), (3990057, -0.9085841178894043), (4057789, -0.9086602330207825), (8729219, -0.9086850881576538), (313542, -0.9091039896011353), (4693968, -0.9091842174530029), (6889045, -0.9095267057418823), (4216338, -0.9095360040664673), (2535148, -0.9096599221229553), (1402968, -0.909906268119812), (1485834, -0.9099485278129578), (7546318, -0.9100956916809082), (2157941, -0.9101443886756897), (2815195, -0.9105063080787659), (1054574, -0.9105682969093323), (5627121, -0.911804735660553), (743823, -0.9119164347648621), (7959719, -0.9121474027633667), (7890528, -0.912312924861908), (3480835, -0.9124938249588013), (5529615, -0.9125102162361145), (7689769, -0.91254723072052), (2703551, -0.9125561714172363), (2363455, -0.9125561714172363), (6593842, -0.9125809669494629), (1054573, -0.9126011729240417), (5748055, -0.9126551151275635), (4745495, -0.9126790165901184), (4974272, -0.9131916165351868), (2183760, -0.9132694005966187), (2044856, -0.9133868217468262), (4407173, -0.9140247702598572), (1286489, -0.9146475791931152), (3026991, -0.9147453904151917), (7762121, -0.9148503541946411), (5203156, -0.915014922618866), (8486209, -0.9151566028594971), (5384769, -0.9153351187705994), (5141222, -0.9158070087432861), (1785405, -0.9160372614860535), (5362617, -0.9161104559898376), (5188747, -0.9162370562553406), (4448644, -0.9163317680358887), (313541, -0.9169647097587585), (2735952, -0.9169924259185791), (8367584, -0.9176371097564697), (2287377, -0.9179320931434631), (7136664, -0.9180295467376709), (8729108, -0.9180295467376709), (6300177, -0.9181100130081177), (5418406, -0.9185165166854858), (4107792, -0.9185372591018677), (347485, -0.9185453653335571), (2305872, -0.9190278053283691), (7437754, -0.9193046689033508), (2946086, -0.9197747707366943), (6384497, -0.9201616644859314), (292365, -0.9201736450195312), (4221092, -0.9204592108726501), (5755086, -0.920730471611023), (7900782, -0.9207758903503418), (4745838, -0.9207803606987), (8594048, -0.9208462238311768), (1765035, -0.9210674166679382), (1783158, -0.9211174249649048), (6824595, -0.9211954474449158), (3685682, -0.9213471412658691), (7385217, -0.9213666319847107), (1280237, -0.9214440584182739), (8503447, -0.9218493103981018), (457995, -0.9219039678573608), (340020, -0.9221442341804504), (5261262, -0.9222009778022766), (3648209, -0.9225583672523499), (5781998, -0.9231812357902527), (4072069, -0.9234117269515991), (313540, -0.9236750602722168), (4927231, -0.9239758253097534), (4205797, -0.924135148525238), (2617202, -0.924356997013092), (1310683, -0.925298273563385), (8330515, -0.9254034757614136), (555336, -0.9255561232566833), (4665977, -0.925869882106781), (8643237, -0.9261006116867065), (1275671, -0.9263548851013184), (5962327, -0.9267686009407043), (2834870, -0.926800549030304), (8352829, -0.9270152449607849), (2800891, -0.9270344376564026), (2871938, -0.9275264143943787), (8129981, -0.9275560975074768), (770749, -0.9278362989425659), (5514587, -0.9281134009361267), (8630091, -0.9284074306488037), (1411655, -0.9284986257553101), (7910205, -0.9285896420478821), (4464732, -0.9285925626754761), (7501823, -0.928676962852478), (6021906, -0.9288135170936584), (6091176, -0.9288195967674255), (8393639, -0.9289165139198303), (2001933, -0.929241955280304), (806849, -0.9299426674842834), (6220189, -0.9299508333206177), (7974452, -0.9302608370780945), (5514589, -0.9303969144821167), (2815191, -0.9305185079574585), (6302495, -0.9307405948638916), (6790426, -0.9312252998352051), (1536646, -0.9314002990722656), (3404362, -0.9314590692520142), (8092780, -0.9314907193183899), (7385220, -0.9315804243087769), (2145570, -0.9325449466705322), (6596269, -0.9328621625900269), (3088434, -0.9329765439033508), (4841345, -0.9337560534477234), (8429670, -0.9340791702270508), (4991111, -0.9341515898704529), (1136523, -0.9344856142997742), (1536645, -0.9351570010185242), (3673403, -0.935837984085083), (4162525, -0.9362035989761353), (5689888, -0.9364654421806335), (7764038, -0.9368049502372742), (7118878, -0.9368840456008911), (631944, -0.9374983310699463), (2086810, -0.9375463724136353), (1454812, -0.9376360774040222), (556888, -0.9377887845039368), (8729215, -0.9382151961326599), (4069635, -0.9384562373161316), (4615569, -0.9385747909545898), (2714586, -0.939041256904602), (3419949, -0.939121425151825), (67631, -0.9393836855888367), (4628480, -0.9398317933082581), (520325, -0.9402759075164795), (8092783, -0.9403683543205261), (4428437, -0.940586268901825), (4644428, -0.9406466484069824), (1857394, -0.9406766295433044), (8092782, -0.9410650730133057), (8704628, -0.9411277174949646), (3565682, -0.941291093826294), (1647679, -0.9414325952529907), (663673, -0.9414718747138977), (1541301, -0.9415009617805481), (959608, -0.9415932297706604), (864474, -0.9422082901000977), (826113, -0.9422321915626526), (3019503, -0.9426823258399963), (2052005, -0.9427118897438049), (7792475, -0.9437942504882812), (7227040, -0.9445177912712097), (980376, -0.9447663426399231), (81800, -0.944972038269043), (7024380, -0.9458578824996948), (582602, -0.9459040760993958), (5313809, -0.9465300440788269), (5947077, -0.9470624923706055), (6601849, -0.9475371241569519), (5124535, -0.9481879472732544), (5514521, -0.9491581320762634), (3764193, -0.9492320418357849), (277312, -0.9495833516120911), (5729988, -0.9507144093513489), (4116705, -0.951180100440979), (8718297, -0.9517939686775208), (7147067, -0.9517939686775208), (7424167, -0.9517939686775208), (8128790, -0.9518149495124817), (1954468, -0.9526865482330322), (3621663, -0.9528815746307373), (5707289, -0.9552602171897888), (5671289, -0.9578747749328613), (3692925, -0.9587350487709045), (2714589, -0.9591748714447021), (8404887, -0.9600956439971924), (1396712, -0.9605475068092346), (4561426, -0.9608139395713806), (156328, -0.9609092473983765), (7368430, -0.961976945400238), (6790419, -0.9648686051368713), (6147931, -0.9651830196380615), (3436898, -0.9660225510597229), (5635512, -0.9666962027549744), (1077449, -0.9677416086196899), (61756, -0.9702970385551453), (1077453, -0.97121661901474), (1434662, -0.9712786078453064), (8173878, -0.9720174074172974), (4055617, -0.9735063910484314), (3692926, -0.9754683971405029), (2922427, -0.9755793809890747), (2515079, -0.9765201210975647), (3404360, -0.9770092964172363), (1911054, -0.9785690903663635), (5323737, -0.9799241423606873), (4395662, -0.9801417589187622), (459398, -0.9822450280189514), (3304769, -0.9838005900382996), (913799, -0.984600305557251), (6792385, -0.9848545789718628)]\n"
     ]
    }
   ],
   "source": [
    "result_dict = test_loader(loaded_net, CURRENT_DEVICE, test_batch, top_dict, query_test_dict, passage_dict, rating_dict)\n",
    "qids = list(result_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "with open('/home/jianx/data/trec_eval/300_1500_100_0.01_256.teIn', 'w+') as f:\n",
    "    for qid in qids:\n",
    "        for rank, item in enumerate(sorted(result_dict[qid].items(), key=lambda x: (x[1], [-1, 1][random.randrange(2)]), reverse=True)):\n",
    "            f.write(\"{}\\tQ0\\t{}\\t{}\\t{}\\trun-id\\n\".format(qid, item[0],rank+1, item[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03413576336435846\n",
      "0.09814336533307344\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "all_scores = []\n",
    "num_95 = 0\n",
    "num_neg95 = 0\n",
    "for i in qids:\n",
    "    for item in sorted(result_dict[i].items(), key=lambda x: (x[1], [-1, 1][random.randrange(2)]), reverse=True):\n",
    "        all_scores.append(item[1])\n",
    "        if item[1] > 0.95:\n",
    "            num_95+=1\n",
    "        if item[1] < -0.95:\n",
    "            num_neg95 += 1\n",
    "plt.hist(all_scores, bins=20)\n",
    "plt.show()\n",
    "print(num_95/len(all_scores))\n",
    "print(num_neg95/len(all_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3551618, 2009615, 4408691, 1863056, 83456, 555080, 6105784, 6895496, 3551621, 4827423]\n"
     ]
    }
   ],
   "source": [
    "top_pids = []\n",
    "qid = 1\n",
    "for i in range(10):\n",
    "    top_pids.append(sorted(result_dict[qids[qid]].items(), key=lambda x: (x[1], [-1, 1][random.randrange(2)]), reverse=True)[i][0])\n",
    "print(top_pids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([304., 191.,  60.,  51.,  47.,  33.,  37.,  44.,  59., 174.]),\n array([-9.97311234e-01, -7.97699982e-01, -5.98088729e-01, -3.98477477e-01,\n        -1.98866224e-01,  7.45028257e-04,  2.00356281e-01,  3.99967533e-01,\n         5.99578786e-01,  7.99190038e-01,  9.98801291e-01]),\n <a list of 10 Patch objects>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result0 = pd.DataFrame.from_dict(sorted(result_dict[qids[11]].items(), key=lambda x: (x[1], [-1, 1][random.randrange(2)]), reverse=True))\n",
    "plt.hist(result0[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855410\n",
      "[0.0, 0.0, 0.6950477058805403, 0.031218489329128234, 0.1777898011244921, 0.02613275632622511, 0.034715610968388634, 0.0735874413409925, 0.0, 0.0636207881989517, 0.20778411473733654, 0.0, 0.0, 0.03668196104968002, 0.1454634185182333, 0.0, 0.0, 0.0767023408078252, 0.6325414799409711, 0.10529614491368275, 0.0, 0.10414512749449265, 0.0, 0.0, 0.22009176629808014, 0.0, 0.147053877022001, 0.14016605921614103, 0.1687615402048088, 0.0, 0.22009176629808017, 0.0, 0.13498882138167081, 0.0, 0.5067194034650795, 0.0, 0.8304503542647043, 0.02959618500861199, 0.28875014033780383, 0.206415932235089, 0.04269569655114159, 0.0, 0.05886610400269325]\n",
      "0.12570639132364755 0.14883720930232555 0.31934597381525837\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_ndcg_precision_rr(true_dict, test_dict, rank):\n",
    "    sorted_result = sorted(test_dict.items(), key=lambda x: (x[1], [-1,1][random.randrange(2)]), reverse=True)\n",
    "    original_rank = rank\n",
    "    rank = min(rank, len(sorted_result))\n",
    "    cumulative_gain = 0\n",
    "    ideal_dict = true_dict\n",
    "    num_positive = 0\n",
    "    rr = float(\"NaN\")\n",
    "    for i in range(len(sorted_result)):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            num_positive += 1\n",
    "    sorted_result = sorted(test_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        relevance = 0\n",
    "        if pid in true_dict:\n",
    "            relevance = true_dict[pid]\n",
    "        ideal_dict[pid] = relevance\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        cumulative_gain += discounted_gain\n",
    "    sorted_ideal = sorted(ideal_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ideal_gain = 0\n",
    "    for i in range(rank):\n",
    "        relevance = sorted_ideal[i][1]\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        ideal_gain += discounted_gain\n",
    "    ndcg = 0\n",
    "    if ideal_gain != 0:\n",
    "         ndcg = cumulative_gain / ideal_gain\n",
    "    return ndcg, num_positive / original_rank, rr\n",
    "import numpy as np\n",
    "result_ndcg = []\n",
    "result_prec = []\n",
    "result_rr = []\n",
    "for qid in qids:\n",
    "    if len(result_dict[qid]) < 10:\n",
    "        print(qid)\n",
    "    ndcg, prec, rr = get_ndcg_precision_rr(rating_dict[qid], result_dict[qid], 10)\n",
    "    result_ndcg.append(ndcg)\n",
    "    result_prec.append(prec)\n",
    "    result_rr.append(rr)\n",
    "print(result_ndcg)\n",
    "avg_ndcg = np.nanmean(result_ndcg)\n",
    "avg_prec = np.nanmean(result_prec)\n",
    "avg_rr = np.nanmean(result_rr)\n",
    "print(avg_ndcg,avg_prec,avg_rr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8975946307182312\n",
      "tensor([-3.0296e+03, -5.2848e+04,  2.3425e-02,  6.3025e-02, -1.0471e-01,\n",
      "        -1.2495e+03,  2.3125e+04,  6.2536e-02,  1.3906e-01,  2.3375e+04,\n",
      "        -2.5828e+04,  4.8552e+02, -4.4572e+03, -2.1202e+04, -2.2999e-02,\n",
      "         9.1718e-02, -4.9721e+04, -4.0220e+03,  3.5009e-01, -2.2760e+04,\n",
      "        -1.8646e+04,  1.6650e+03, -4.0550e+04, -2.2024e+04,  5.0473e+04,\n",
      "        -4.8476e+04,  1.4154e+04, -1.0826e+03, -6.3183e+03,  1.4134e-01,\n",
      "        -8.9433e+03,  3.2223e+04, -9.0528e+03,  5.4107e+04,  4.3253e+04,\n",
      "        -1.0032e+04, -9.7527e+03, -4.7771e+04,  2.5884e+04, -7.8262e+03,\n",
      "         2.0455e-01,  5.1378e+04,  9.3307e+03,  6.5136e+03,  1.5810e+04,\n",
      "         1.3519e-02, -1.0916e+04, -9.4892e+02,  4.7940e+03,  8.1336e+03,\n",
      "        -3.5506e+04,  5.5301e+04, -2.1024e+04, -7.8287e+03,  2.0133e+04,\n",
      "         5.7350e+03,  4.4025e+04,  2.8542e-02,  2.8935e+04,  2.3223e+04,\n",
      "        -4.4460e+04, -1.4056e+04,  4.0348e+04,  8.1690e+03, -2.3161e-02,\n",
      "         9.8422e+03,  7.1057e+03, -9.1942e+03, -2.2423e+04, -8.0939e+03,\n",
      "         4.2322e+04,  5.0241e+04, -2.5472e+04,  3.2095e+04, -8.9436e+03,\n",
      "        -1.9132e+04,  1.0760e-01, -5.8193e+03,  1.6190e-01,  3.4069e+04,\n",
      "        -4.6795e+04,  9.4634e+03, -4.8962e-02,  6.5380e+03,  1.0304e+04,\n",
      "        -4.9744e+04,  1.3808e+04,  3.5927e-01,  2.7472e+04,  4.7626e+04,\n",
      "        -2.1491e+04, -3.8948e+04,  7.4074e+03,  3.9344e+04,  1.0179e+04,\n",
      "        -1.4754e+04,  1.5857e+03, -4.9744e+04, -9.0342e-01,  2.1288e+04,\n",
      "         4.7359e+04,  1.3875e+00, -9.5215e+03,  2.1155e+04,  4.0580e+04,\n",
      "        -4.3081e+04, -4.2061e+04,  5.2997e+02,  1.5925e-02, -3.7329e+04,\n",
      "         3.5345e+04,  1.4694e-02, -3.5823e+04,  2.2858e+04, -4.7012e+04,\n",
      "         2.6937e+04,  5.3057e+04, -4.2511e+04, -3.1509e+03, -4.0389e+04,\n",
      "         7.6298e-04, -4.8525e+04,  1.5963e+04, -4.5677e+03,  3.5625e+02,\n",
      "        -7.2132e+03,  4.7744e+04,  3.1560e+04, -4.3249e+04,  1.6687e+04,\n",
      "         8.6056e-02,  4.5908e+03, -4.9157e+03,  2.1283e+04,  1.1730e-01,\n",
      "        -3.1044e+04,  1.0141e+04, -5.0848e+04, -6.5922e+03, -1.8340e+04,\n",
      "        -4.6900e+04,  1.0329e-01, -1.3038e+04, -4.1153e+04,  1.6818e+04,\n",
      "         2.6289e+04, -5.0982e+03,  1.0356e+04,  4.8277e+04,  2.6474e+04,\n",
      "         6.6768e+03,  6.3278e+03,  1.8699e+04,  9.0486e+03,  1.4566e+02,\n",
      "        -1.7359e+04, -4.7979e-02, -4.9756e+04, -4.5747e-01,  5.3286e+04,\n",
      "         1.1778e+04,  1.2050e+04,  3.4422e+04,  2.1904e+04,  1.1007e+04,\n",
      "         3.7828e+03,  4.3447e+04,  2.9360e+03,  6.2490e+03,  1.0563e+04,\n",
      "         3.6384e+03, -2.9015e+04, -1.5869e+03,  4.0812e+04,  3.7580e+04,\n",
      "         2.0917e-01,  4.4111e+03,  4.0250e+04,  2.0930e-01, -5.6291e+04,\n",
      "         3.6062e+04, -2.5000e+04,  3.2612e-02, -2.4053e+04,  3.3958e+04,\n",
      "         2.7531e+04, -1.8132e+04, -1.2532e+04,  1.2572e-01,  1.5689e+04,\n",
      "        -1.1542e+04,  5.2027e+04, -2.3579e+04, -1.9040e-01, -4.7717e+03,\n",
      "         4.7475e+04, -9.8799e+03,  2.3048e+04, -8.3453e+03, -4.3272e+04,\n",
      "        -3.6756e+04, -1.7406e+04, -4.9682e+03, -1.6301e+04, -1.9611e-01,\n",
      "         5.1864e+04,  4.6349e+04,  5.6984e+04,  4.6794e-02, -7.5599e-02,\n",
      "        -2.2177e-01, -1.2275e+04, -5.6982e+04, -1.0564e-01,  9.7305e-02,\n",
      "         3.3499e+04,  3.0186e-03, -2.9046e+04,  4.6723e+04, -2.0410e+04,\n",
      "        -4.7558e-03, -1.5339e+04, -4.7001e-02, -2.5583e+04, -3.5751e+03,\n",
      "        -2.1029e-01, -7.0473e+03,  5.9210e+04, -3.3012e-03,  1.7953e+04,\n",
      "        -1.7747e+03,  1.1340e-01,  3.1822e+04, -3.9843e+02, -3.0053e+04,\n",
      "        -6.4501e-02, -1.8719e+03, -1.7350e+03,  1.6333e+04,  1.9489e+04,\n",
      "        -4.3442e+04, -1.3882e+03,  3.6777e+04,  2.4744e+04, -1.1511e+04,\n",
      "        -1.1171e+04,  4.4891e+03, -2.3507e+04,  2.0668e+04, -4.6430e+04,\n",
      "        -4.1521e+04, -2.7394e+04, -1.3146e+04,  5.2022e+04,  3.0565e+04,\n",
      "        -2.1610e+04], device='cuda:0')\n",
      "tensor([ 1.0556e+05,  2.2740e+05,  1.7599e-02,  4.7898e-02, -8.0411e-02,\n",
      "        -6.1186e+04, -1.5594e+05,  4.8673e-02,  1.0582e-01, -4.1300e+04,\n",
      "         1.0240e+05, -6.0655e+04, -6.3560e+03,  1.1556e+05, -1.7786e-02,\n",
      "         7.0112e-02,  1.6768e+05, -2.1145e+04,  2.6550e-01,  9.9007e+04,\n",
      "        -4.9371e+03,  4.0963e+04,  1.2323e+05,  1.3447e+03, -1.8159e+05,\n",
      "         2.0458e+05, -1.1286e+03, -7.7397e+04, -4.6056e+04,  1.0795e-01,\n",
      "        -3.3751e+04, -5.5082e+04,  4.8833e+03, -1.7931e+05, -1.1999e+05,\n",
      "         4.7733e+04,  5.0250e+04,  1.7207e+05, -3.4460e+04, -5.6201e+04,\n",
      "         1.5328e-01, -1.3980e+05, -1.4223e+03,  2.4119e+04, -1.2746e+05,\n",
      "         1.1099e-02,  1.2676e+05, -2.2154e+03, -2.5340e+04,  5.1240e+04,\n",
      "         9.6266e+04, -2.0559e+05,  7.7350e+04,  1.2108e+05, -7.5114e+04,\n",
      "        -9.1533e+04, -2.1070e+05,  2.2284e-02, -4.1726e+04, -2.3239e+04,\n",
      "         1.8905e+05,  3.7238e+04, -1.8577e+05, -5.1023e+04, -1.7622e-02,\n",
      "         2.4466e+04, -7.5012e+04, -5.6963e+04,  2.8190e+04, -2.3409e+04,\n",
      "        -1.7287e+05, -1.3504e+05,  1.6441e+05, -9.5778e+04, -2.1489e+04,\n",
      "         5.3484e+04,  8.1971e-02,  6.7922e+04,  1.2471e-01, -8.2469e+04,\n",
      "         1.6778e+05,  2.7922e+04, -3.7753e-02,  6.5503e+04,  6.7322e+04,\n",
      "         1.4869e+05, -9.9660e+04,  2.7250e-01, -1.0293e+05, -2.1970e+05,\n",
      "         1.4491e+05,  8.7969e+04, -9.6749e+04, -1.3620e+05, -1.0338e+05,\n",
      "        -2.8709e+04,  8.8748e+04,  2.0228e+05, -6.6668e-01, -3.9450e+04,\n",
      "        -1.6301e+05,  1.0511e+00,  7.0320e+04, -2.0460e+04, -1.9834e+05,\n",
      "         1.4721e+05,  8.6417e+04,  3.7553e+04,  1.3067e-02,  1.8559e+05,\n",
      "        -8.9837e+04,  1.1489e-02,  1.5139e+05,  1.8131e+04,  1.7114e+05,\n",
      "        -7.4014e+04, -2.1869e+05,  1.9359e+05,  7.8076e+03,  1.5246e+05,\n",
      "         6.2822e-05,  1.4616e+05, -1.1088e+05, -2.7023e+04,  6.7067e+04,\n",
      "        -1.0774e+03, -1.3909e+05, -6.4696e+04,  1.1406e+05, -1.6557e+04,\n",
      "         6.6743e-02, -6.8869e+04, -5.2885e+04, -1.6041e+05,  8.9828e-02,\n",
      "         3.5875e+04, -1.2995e+05,  1.6350e+05,  9.1161e+04, -9.7916e+03,\n",
      "         1.8850e+05,  7.9480e-02, -4.1903e+04,  1.8008e+05, -1.0471e+04,\n",
      "        -4.0425e+04, -4.6087e+04,  2.9838e+03, -1.8091e+05, -5.6073e+04,\n",
      "         1.7562e+04, -7.5239e+04, -8.2790e+04,  1.8622e+04,  5.2326e+04,\n",
      "         3.0964e+04, -3.7035e-02,  2.1358e+05, -3.5113e-01, -2.0151e+05,\n",
      "        -8.6062e+03, -3.9334e+04, -1.3773e+05, -7.7069e+04, -9.3118e+04,\n",
      "        -6.7300e+04, -2.0318e+05, -8.6757e+03, -2.0689e+03,  6.6503e+04,\n",
      "        -5.2686e+04,  1.4368e+05, -3.4352e+04, -1.0470e+05, -1.3600e+05,\n",
      "         1.6029e-01,  6.4470e+04, -1.1840e+05,  1.5898e-01,  1.8565e+05,\n",
      "        -7.1998e+04,  1.1360e+05,  2.5197e-02,  8.9124e+04, -1.0430e+05,\n",
      "        -7.4749e+04,  9.4840e+04,  9.3336e+04,  9.5708e-02, -6.2513e+04,\n",
      "        -1.3008e+04, -1.9861e+05,  1.3140e+04, -1.4562e-01,  1.0990e+05,\n",
      "        -2.2360e+05, -6.0285e+04, -1.3696e+05,  6.6690e+03,  1.7422e+05,\n",
      "         1.7797e+05,  1.1952e+05,  7.4974e+04,  4.8000e+04, -1.5004e-01,\n",
      "        -2.1692e+05, -1.7630e+05, -2.0196e+05,  3.5729e-02, -5.7692e-02,\n",
      "        -1.6844e-01,  8.7184e+04,  2.2184e+05, -8.0766e-02,  7.3860e-02,\n",
      "        -4.1346e+04,  2.9068e-03,  9.0280e+04, -2.0829e+05,  1.0549e+05,\n",
      "        -3.3814e-03,  7.4630e+04, -3.6944e-02,  1.2233e+05, -5.6840e+04,\n",
      "        -1.6174e-01,  1.1197e+05, -2.1638e+05, -2.1802e-03, -1.3340e+05,\n",
      "        -6.1177e+04,  8.6598e-02, -1.3329e+05, -3.0224e+04,  1.5933e+05,\n",
      "        -4.9096e-02,  8.9787e+04,  1.0542e+05,  6.4239e+03, -1.0303e+05,\n",
      "         2.1460e+05, -7.9980e+04, -1.5738e+05, -6.5582e+04, -1.2411e+04,\n",
      "         1.0056e+05,  6.3385e+04,  9.3114e+04, -1.0800e+05,  1.9368e+05,\n",
      "         1.2165e+05,  1.5749e+05,  8.4102e+04, -2.2553e+05, -3.8760e+04,\n",
      "        -2.0406e+03], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_qid = 1133167\n",
    "test_pid = 6112590\n",
    "test_q_embed = net(generate_sparse(query_test_dict[test_qid]).to(CURRENT_DEVICE)).detach()\n",
    "test_p_embed = net(generate_sparse(passage_dict[test_pid]).to(CURRENT_DEVICE)).detach()\n",
    "test_score = torch.cosine_similarity(test_q_embed.unsqueeze(0), test_p_embed.unsqueeze(0)).item()\n",
    "print(test_score)\n",
    "print(test_p_embed)\n",
    "\n",
    "print(test_q_embed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}