{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSSM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "              0                          1\n0        121352                 1924 2363 \n1        634306         29570 321 193 198 \n2        920825       131 8242 1880 36968 \n3        510633                4711 38 31 \n4        737889                  39755 99 \n...         ...                        ...\n808726   633855          752 703 2420 321 \n808727  1059728            6398 36572 136 \n808728   210839                   1087 22 \n808729   908165           4 685 45818 233 \n808730    50393  294 3136 11405 1704 1424 \n\n[808731 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>121352</td>\n      <td>1924 2363</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>634306</td>\n      <td>29570 321 193 198</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>920825</td>\n      <td>131 8242 1880 36968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>510633</td>\n      <td>4711 38 31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737889</td>\n      <td>39755 99</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>808726</th>\n      <td>633855</td>\n      <td>752 703 2420 321</td>\n    </tr>\n    <tr>\n      <th>808727</th>\n      <td>1059728</td>\n      <td>6398 36572 136</td>\n    </tr>\n    <tr>\n      <th>808728</th>\n      <td>210839</td>\n      <td>1087 22</td>\n    </tr>\n    <tr>\n      <th>808729</th>\n      <td>908165</td>\n      <td>4 685 45818 233</td>\n    </tr>\n    <tr>\n      <th>808730</th>\n      <td>50393</td>\n      <td>294 3136 11405 1704 1424</td>\n    </tr>\n  </tbody>\n</table>\n<p>808731 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0        0\n1    15181\ndtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = pd.read_csv(\"~/data/queries_train_indices.csv\", header = None)\n",
    "display(query)\n",
    "query.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sparse_to_dense(idx, vocab_len):\n",
    "    index_tensor = torch.LongTensor([idx])\n",
    "    value_tensor = torch.Tensor([1]*len(idx))\n",
    "    dense_tensor = torch.sparse.FloatTensor(index_tensor, value_tensor, torch.Size([vocab_len,])).to_dense()\n",
    "    return dense_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# test case:\n",
    "top_dict = {1:[11,12,13,14], 2:[21,22,23,24]}\n",
    "rating_dict = {1:{11:3,12:2,13:1}, 2:{21:2,23:1}}\n",
    "query_test_dict = {1:[0,5,2], 2:[1,3,4]}\n",
    "passage_dict = {11:[0,1,2,3,4], 12:[0,3,3,4], 13:[0,1], 14:[1,1,3],21:[1,2,1], 22:[0,2,5], 23:[1,2,2], 24:[0,0,5]}\n",
    "result_dict = {1:{11:0.9, 12: 0, 13:0.5, 14:0.1}, 2:{21:0.3, 22: 0.6, 23:0.9, 24:0}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import math\n",
    "def get_ndcg_precision_rr(true_dict, test_dict, rank):\n",
    "    sorted_result = sorted(test_dict.items(), key=lambda x: (x[1], [-1,1][random.randrange(2)]), reverse=True)\n",
    "    original_rank = rank\n",
    "    rank = min(rank, len(sorted_result))\n",
    "    cumulative_gain = 0\n",
    "    ideal_dict = {}\n",
    "    num_positive = 0\n",
    "    rr = float(\"NaN\")\n",
    "    for i in range(len(sorted_result)):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            num_positive += 1\n",
    "    sorted_result = sorted(test_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        relevance = 0\n",
    "        if pid in true_dict:\n",
    "            relevance = true_dict[pid]\n",
    "        ideal_dict[pid] = relevance\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        cumulative_gain += discounted_gain\n",
    "    sorted_ideal = sorted(ideal_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ideal_gain = 0\n",
    "    for i in range(rank):\n",
    "        relevance = sorted_ideal[i][1]\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        ideal_gain += discounted_gain\n",
    "    ndcg = 0\n",
    "    if ideal_gain != 0:\n",
    "         ndcg = cumulative_gain / ideal_gain\n",
    "    return ndcg, num_positive / original_rank, rr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9608081943360617, 0.8333333333333334, 1.0)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "result_dict = {1:10, 2:9, 3:8, 4:7, 5:6, 6:5}\n",
    "rating_dict = {1:3, 2:2, 3:3, 5:1, 6:2, 7:3, 8:2}\n",
    "get_ndcg_precision_rr(rating_dict, result_dict, 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cosine_similarity(torch.FloatTensor([0,1,0]).unsqueeze(0),torch.FloatTensor([1,0,0]).unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "sys.path.insert(0, '/home/jianx/search-exposure/')\n",
    "from load_data import obj_reader\n",
    "from load_data import obj_writer\n",
    "\n",
    "CURRENT_GPU = 0\n",
    "if not os.path.exists(GPU_ROOT):\n",
    "    obj_writer([0,0,0,0], GPU_ROOT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 3]\n",
      "0\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "def select_device():\n",
    "    argmin = -1\n",
    "    if not torch.cuda.is_available():\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        gpu_usage_list = obj_reader(GPU_ROOT)\n",
    "        min = 100000\n",
    "        argmin = 0\n",
    "        for i, count in enumerate(gpu_usage_list):\n",
    "            if count < min:\n",
    "                argmin = i\n",
    "                min = count\n",
    "        gpu_usage_list[argmin] += 1\n",
    "        print(gpu_usage_list)\n",
    "        device = torch.device(\"cuda:\" + str(argmin))\n",
    "        obj_writer(gpu_usage_list, GPU_ROOT)\n",
    "    return device,argmin\n",
    "\n",
    "def cleanup_gpu_list():\n",
    "    gpu_usage_list = obj_reader(GPU_ROOT)\n",
    "    gpu_usage_list[CURRENT_GPU] -=1\n",
    "    obj_writer(gpu_usage_list, GPU_ROOT)\n",
    "device,CURRENT_GPU = select_device()\n",
    "print(CURRENT_GPU)\n",
    "print(torch.cuda.get_device_name(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "cleanup_gpu_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_results(results, qrels):\n",
    "    mrr = 0\n",
    "    ncg = 0\n",
    "    ndcg = 0\n",
    "    for qid, docs in results.items():\n",
    "        if qid not in qrels:\n",
    "            continue\n",
    "        qrels_q = qrels[qid]\n",
    "        gains = [qrels_q.get(doc[0], 0) for doc in docs]\n",
    "        ideal_gains = sorted(list(qrels_q.values()), reverse=True)\n",
    "        max_metric_pos_disc = min(len(gains), 10)\n",
    "        max_metric_pos = min(len(gains), 100 if task_docs else 1000)\n",
    "        ideal_max_metric_pos_disc = min(len(ideal_gains), 10)\n",
    "        ideal_max_metric_pos = min(len(ideal_gains), 100 if task_docs else 1000)\n",
    "        cg = sum([gains[i] for i in range(max_metric_pos)])\n",
    "        dcg = sum([gains[i] / math.log2(i + 2) for i in range(max_metric_pos_disc)])\n",
    "        ideal_cg = sum([ideal_gains[i] for i in range(ideal_max_metric_pos)])\n",
    "        ideal_dcg = sum([ideal_gains[i] / math.log2(i + 2) for i in range(ideal_max_metric_pos_disc)])\n",
    "        ncg += cg / ideal_cg if ideal_cg > 0 else 0\n",
    "        ndcg += dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "        try:\n",
    "            if task_docs:\n",
    "                mrr += 1 / ([1 if gain > 1 else 0 for gain in gains].index(1) + 1)\n",
    "            else:\n",
    "                mrr += 1 / ([min(gain, 1) for gain in gains].index(1) + 1)\n",
    "        except Exception:\n",
    "            pass\n",
    "    mrr /= len(qrels)\n",
    "    ncg /= len(qrels)\n",
    "    ndcg /= len(qrels)\n",
    "    return mrr, ncg, ndcg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}