{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSSM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "              0                          1\n0        121352                 1924 2363 \n1        634306         29570 321 193 198 \n2        920825       131 8242 1880 36968 \n3        510633                4711 38 31 \n4        737889                  39755 99 \n...         ...                        ...\n808726   633855          752 703 2420 321 \n808727  1059728            6398 36572 136 \n808728   210839                   1087 22 \n808729   908165           4 685 45818 233 \n808730    50393  294 3136 11405 1704 1424 \n\n[808731 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>121352</td>\n      <td>1924 2363</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>634306</td>\n      <td>29570 321 193 198</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>920825</td>\n      <td>131 8242 1880 36968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>510633</td>\n      <td>4711 38 31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737889</td>\n      <td>39755 99</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>808726</th>\n      <td>633855</td>\n      <td>752 703 2420 321</td>\n    </tr>\n    <tr>\n      <th>808727</th>\n      <td>1059728</td>\n      <td>6398 36572 136</td>\n    </tr>\n    <tr>\n      <th>808728</th>\n      <td>210839</td>\n      <td>1087 22</td>\n    </tr>\n    <tr>\n      <th>808729</th>\n      <td>908165</td>\n      <td>4 685 45818 233</td>\n    </tr>\n    <tr>\n      <th>808730</th>\n      <td>50393</td>\n      <td>294 3136 11405 1704 1424</td>\n    </tr>\n  </tbody>\n</table>\n<p>808731 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0        0\n1    15181\ndtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = pd.read_csv(\"~/data/queries_train_indices.csv\", header = None)\n",
    "display(query)\n",
    "query.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sparse_to_dense(idx, vocab_len):\n",
    "    index_tensor = torch.LongTensor([idx])\n",
    "    value_tensor = torch.Tensor([1]*len(idx))\n",
    "    dense_tensor = torch.sparse.FloatTensor(index_tensor, value_tensor, torch.Size([vocab_len,])).to_dense()\n",
    "    return dense_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# test case:\n",
    "top_dict = {1:[11,12,13,14], 2:[21,22,23,24]}\n",
    "rating_dict = {1:{11:3,12:2,13:1}, 2:{21:2,23:1}}\n",
    "query_test_dict = {1:[0,5,2], 2:[1,3,4]}\n",
    "passage_dict = {11:[0,1,2,3,4], 12:[0,3,3,4], 13:[0,1], 14:[1,1,3],21:[1,2,1], 22:[0,2,5], 23:[1,2,2], 24:[0,0,5]}\n",
    "result_dict = {1:{11:0.9, 12: 0, 13:0.5, 14:0.1}, 2:{21:0.3, 22: 0.6, 23:0.9, 24:0}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import math\n",
    "def get_ndcg_precision_rr(true_dict, test_dict, rank):\n",
    "    sorted_result = sorted(test_dict.items(), key=lambda x: (x[1], [-1,1][random.randrange(2)]), reverse=True)\n",
    "    original_rank = rank\n",
    "    rank = min(rank, len(sorted_result))\n",
    "    cumulative_gain = 0\n",
    "    ideal_dict = {}\n",
    "    num_positive = 0\n",
    "    rr = float(\"NaN\")\n",
    "    for i in range(len(sorted_result)):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            num_positive += 1\n",
    "    sorted_result = sorted(test_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        relevance = 0\n",
    "        if pid in true_dict:\n",
    "            relevance = true_dict[pid]\n",
    "        ideal_dict[pid] = relevance\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        cumulative_gain += discounted_gain\n",
    "    sorted_ideal = sorted(ideal_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ideal_gain = 0\n",
    "    for i in range(rank):\n",
    "        relevance = sorted_ideal[i][1]\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        ideal_gain += discounted_gain\n",
    "    ndcg = 0\n",
    "    if ideal_gain != 0:\n",
    "         ndcg = cumulative_gain / ideal_gain\n",
    "    return ndcg, num_positive / original_rank, rr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9608081943360617, 0.8333333333333334, 1.0)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "result_dict = {1:10, 2:9, 3:8, 4:7, 5:6, 6:5}\n",
    "rating_dict = {1:3, 2:2, 3:3, 5:1, 6:2, 7:3, 8:2}\n",
    "get_ndcg_precision_rr(rating_dict, result_dict, 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cosine_similarity(torch.FloatTensor([0,1,0]).unsqueeze(0),torch.FloatTensor([1,0,0]).unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "sys.path.insert(0, '/home/jianx/search-exposure/')\n",
    "from load_data import obj_reader\n",
    "from load_data import obj_writer\n",
    "\n",
    "CURRENT_GPU = 0\n",
    "if not os.path.exists(GPU_ROOT):\n",
    "    obj_writer([0,0,0,0], GPU_ROOT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 3]\n",
      "0\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "def select_device():\n",
    "    argmin = -1\n",
    "    if not torch.cuda.is_available():\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        gpu_usage_list = obj_reader(GPU_ROOT)\n",
    "        min = 100000\n",
    "        argmin = 0\n",
    "        for i, count in enumerate(gpu_usage_list):\n",
    "            if count < min:\n",
    "                argmin = i\n",
    "                min = count\n",
    "        gpu_usage_list[argmin] += 1\n",
    "        print(gpu_usage_list)\n",
    "        device = torch.device(\"cuda:\" + str(argmin))\n",
    "        obj_writer(gpu_usage_list, GPU_ROOT)\n",
    "    return device,argmin\n",
    "\n",
    "def cleanup_gpu_list():\n",
    "    gpu_usage_list = obj_reader(GPU_ROOT)\n",
    "    gpu_usage_list[CURRENT_GPU] -=1\n",
    "    obj_writer(gpu_usage_list, GPU_ROOT)\n",
    "device,CURRENT_GPU = select_device()\n",
    "print(CURRENT_GPU)\n",
    "print(torch.cuda.get_device_name(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "cleanup_gpu_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_results(results, qrels):\n",
    "    mrr = 0\n",
    "    ncg = 0\n",
    "    ndcg = 0\n",
    "    for qid, docs in results.items():\n",
    "        if qid not in qrels:\n",
    "            continue\n",
    "        qrels_q = qrels[qid]\n",
    "        gains = [qrels_q.get(doc[0], 0) for doc in docs]\n",
    "        ideal_gains = sorted(list(qrels_q.values()), reverse=True)\n",
    "        max_metric_pos_disc = min(len(gains), 10)\n",
    "        max_metric_pos = min(len(gains), 100 if task_docs else 1000)\n",
    "        ideal_max_metric_pos_disc = min(len(ideal_gains), 10)\n",
    "        ideal_max_metric_pos = min(len(ideal_gains), 100 if task_docs else 1000)\n",
    "        cg = sum([gains[i] for i in range(max_metric_pos)])\n",
    "        dcg = sum([gains[i] / math.log2(i + 2) for i in range(max_metric_pos_disc)])\n",
    "        ideal_cg = sum([ideal_gains[i] for i in range(ideal_max_metric_pos)])\n",
    "        ideal_dcg = sum([ideal_gains[i] / math.log2(i + 2) for i in range(ideal_max_metric_pos_disc)])\n",
    "        ncg += cg / ideal_cg if ideal_cg > 0 else 0\n",
    "        ndcg += dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "        try:\n",
    "            if task_docs:\n",
    "                mrr += 1 / ([1 if gain > 1 else 0 for gain in gains].index(1) + 1)\n",
    "            else:\n",
    "                mrr += 1 / ([min(gain, 1) for gain in gains].index(1) + 1)\n",
    "        except Exception:\n",
    "            pass\n",
    "    mrr /= len(qrels)\n",
    "    ncg /= len(qrels)\n",
    "    ndcg /= len(qrels)\n",
    "    return mrr, ncg, ndcg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jianx/search-exposure/forward_ranker/')\n",
    "import torch\n",
    "from train import generate_sparse\n",
    "from load_data import obj_reader\n",
    "import network\n",
    "from annoy import AnnoyIndex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/home/jianx/data/results/100_1000_1000_0.001_256_10.model\"\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "EMBED_SIZE = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "DSSM(\n  (model): Sequential(\n    (0): Linear(in_features=100000, out_features=64, bias=True)\n    (1): ReLU()\n    (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=64, out_features=64, bias=True)\n    (5): ReLU()\n    (6): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n    (7): Dropout(p=0.1, inplace=False)\n    (8): Linear(in_features=64, out_features=64, bias=True)\n    (9): ReLU()\n    (10): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n    (11): Dropout(p=0.1, inplace=False)\n    (12): Linear(in_features=64, out_features=256, bias=True)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NET = network.DSSM(embed_size=EMBED_SIZE)\n",
    "NET.load_state_dict(torch.load(MODEL_PATH))\n",
    "NET.to(DEVICE)\n",
    "NET.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EMBEDDING_PATH = \"/home/jianx/data/results/passage_embeddings.dict\"\n",
    "passage_embeddings = obj_reader(EMBEDDING_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(passage_embeddings[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "QUERY_TEST_DICT = obj_reader(\"/home/jianx/data/queries_test.dict\")\n",
    "PASSAGE_DICT = obj_reader(\"/home/jianx/data/passages.dict\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "RATING_DICT = obj_reader(\"/home/jianx/data/rel_scores.dict\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Brute Force Full Retrieval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([43, 1, 256])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QIDS = list(RATING_DICT.keys())\n",
    "QUERY_EMBEDDINGS = []\n",
    "for qid in QIDS:\n",
    "    q_seq = QUERY_TEST_DICT[qid]\n",
    "    QUERY_EMBEDDINGS.append(NET(generate_sparse(q_seq).to(DEVICE)).detach())\n",
    "QUERY_EMBEDDING_TENSOR = torch.stack(QUERY_EMBEDDINGS, dim=0).unsqueeze(dim=1)\n",
    "QUERY_EMBEDDING_TENSOR.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19335\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True], device='cuda:1')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(QIDS[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(3, 0))\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n",
      "tensor([[1., 1., 1., 4., 4., 4.],\n",
      "        [2., 2., 2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3., 3., 3.]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "empty = torch.empty([3,0])\n",
    "print(empty)\n",
    "q = torch.FloatTensor([[1,1,1],[2,2,2],[3,3,3]])\n",
    "print(q)\n",
    "p = torch.FloatTensor([[4,4,4],[2,2,2],[3,3,3]])\n",
    "r = torch.cat([empty,q],dim=1)\n",
    "r = torch.cat([r,p],dim=1)\n",
    "print(r)\n",
    "print(r[0].data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]\n"
     ]
    }
   ],
   "source": [
    "pids = [1,2,3,4,5,6,7,8,9,10]\n",
    "pids_2d = []\n",
    "slice_idx = 0\n",
    "while slice_idx + 3 < len(pids):\n",
    "    pid_batch = pids[slice_idx:(slice_idx + 3)]\n",
    "    slice_idx += 3\n",
    "    pids_2d.append(pid_batch)\n",
    "pids_2d.append(pids[slice_idx:])\n",
    "print(pids_2d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 09, 04:26:21] hello\n",
      "100000000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "print(\"[{}] {}\".format(datetime.now(timezone(timedelta(hours=-4))).strftime(\"%b %d, %H:%M:%S\"), \"hello\"), flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}