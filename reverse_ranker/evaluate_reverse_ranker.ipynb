{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load pretrained model\n",
    "# 2. Load query embeddings\n",
    "# 3. Compute corpus output from query embeddings\n",
    "# 4. Concatenate original embeddings with corpus embeddings \n",
    "# 5. Add the new numpy array to Flatindex\n",
    "# 6. Find n nearest queries of a passage\n",
    "# 7. Compare with the groud truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_HIDDEN_NODES = 64\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "DROPOUT_RATE = 0.1\n",
    "FEAT_COUNT = 768\n",
    "\n",
    "\n",
    "# Define the network\n",
    "class CorpusNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size):\n",
    "        super(CorpusNet, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        last_dim = FEAT_COUNT\n",
    "        for i in range(NUM_HIDDEN_LAYERS):\n",
    "            layers.append(nn.Linear(last_dim, NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.LayerNorm(NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.Dropout(p=DROPOUT_RATE))\n",
    "            last_dim = NUM_HIDDEN_NODES\n",
    "        layers.append(nn.Linear(last_dim, embed_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def parameter_count(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CorpusNet(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (11): Dropout(p=0.1, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "PASSAGE_NP_PATH = \"/home/jianx/results/passage_0__emb_p__data_obj_0.pb\"\n",
    "PASSAGE_MAP_PATH = \"/datadrive/jianx/data/annoy/100_ance_passage_map.dict\"\n",
    "QUERY_TRAIN_NP_PATH = \"/home/jianx/results/query_0__emb_p__data_obj_0.pb\"\n",
    "QUERY_MAP_PATH = \"/datadrive/jianx/data/annoy/100_ance_query_train_map.dict\"\n",
    "# REVERSE_RANKER_PATH = \"/home/ruohan/DSSM/search-exposure/reverse_ranker/results/reverse_corpus_features1000_100_1000_0.0001_32.model\"\n",
    "REVERSE_RANKER_PATH = \"/home/ruohan/DSSM/search-exposure/reverse_ranker/results/reverse_corpus_features_not_normalize1000_100_1000_0.0001_32.model\"\n",
    "\n",
    "\n",
    "CURRENT_DEVICE = \"cuda:1\"\n",
    "EMBED_SIZE = 32\n",
    "\n",
    "def obj_reader(path):\n",
    "    with open(path, 'rb') as handle:\n",
    "        return pickle.load(handle, encoding=\"bytes\")\n",
    "\n",
    "# 1. Load pretrained model\n",
    "reverse_ranker = CorpusNet(embed_size=EMBED_SIZE)\n",
    "reverse_ranker.load_state_dict(torch.load(REVERSE_RANKER_PATH))\n",
    "reverse_ranker.to(CURRENT_DEVICE)\n",
    "reverse_ranker.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load query embeddings\n",
    "passage_np = obj_reader(PASSAGE_NP_PATH)\n",
    "pid_mapping = obj_reader(PASSAGE_MAP_PATH)\n",
    "query_np = obj_reader(QUERY_TRAIN_NP_PATH)\n",
    "qid_mapping = obj_reader(QUERY_MAP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_reverse_mapping = {v: k for k, v in pid_mapping.items()}\n",
    "qid_reverse_mapping = {v: k for k, v in qid_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth ranking\n",
    "TRUE_PATH = \"/datadrive/jianx/data/results/all_search_rankings_100_100_flat.csv\"\n",
    "def load_true_dict(k = 100, path = TRUE_PATH):\n",
    "    true_dict = {}\n",
    "    with open(path, \"r\") as file:\n",
    "        for line in file:\n",
    "            qid = int(line.split(\",\")[0])\n",
    "            pid = int(line.split(\",\")[1])\n",
    "            rank = int(line.split(\",\")[2])\n",
    "            if rank > k:\n",
    "                continue\n",
    "            if pid not in true_dict.keys():\n",
    "                true_dict[pid] = {}\n",
    "            true_dict[pid][qid] = rank\n",
    "    return true_dict\n",
    "def load_forward_dict(k = 100, path = TRUE_PATH):\n",
    "    true_dict = {}\n",
    "    with open(path, \"r\") as file:\n",
    "        for line in file:\n",
    "            qid = int(line.split(\",\")[0])\n",
    "            pid = int(line.split(\",\")[1])\n",
    "            rank = int(line.split(\",\")[2])\n",
    "            if rank > k:\n",
    "                continue\n",
    "            if qid not in true_dict.keys():\n",
    "                true_dict[qid] = {}\n",
    "            true_dict[qid][pid] = rank\n",
    "    return true_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_dict_100 = load_forward_dict(k=100)\n",
    "true_dict_100 = load_true_dict(k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compute corpus output from query embeddings\n",
    "# 4. Concatenate original embeddings with corpus embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_np(query_np):\n",
    "    b = 100\n",
    "    n = int(query_np.shape[0]/b) + 1\n",
    "\n",
    "    corpus_output = []\n",
    "    for i in range(n):\n",
    "        start = i * b\n",
    "        end = (i + 1) * b\n",
    "        if i == n-1:\n",
    "            end = query_np.shape[0]\n",
    "        q_embed = query_np[start:end,:]\n",
    "        q_embed = torch.from_numpy(q_embed).to(CURRENT_DEVICE)\n",
    "        corpus_output.append(reverse_ranker(q_embed).detach().cpu().numpy())\n",
    "    corpus_np = np.concatenate(corpus_output[:-1])\n",
    "    corpus_np = np.concatenate((corpus_np, corpus_output[-1]))\n",
    "    query_new_np = np.concatenate((corpus_np, query_np), axis=1)\n",
    "    print(query_new_np.shape)\n",
    "    return query_new_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_np(query_np, passage_np, normalize=True):\n",
    "    query_new_np = transform_np(query_np)\n",
    "    passage_new_np = transform_np(passage_np)\n",
    "    all_new_np = np.concatenate((query_new_np, passage_new_np))\n",
    "    if normalize:\n",
    "        all_new_np = F.normalize(torch.from_numpy(all_new_np)).numpy()\n",
    "    n_query = query_new_np.shape[0]\n",
    "    query_new_np = all_new_np[:n_query,:]\n",
    "    passage_new_np = all_new_np[n_query:,:]\n",
    "    return query_new_np, passage_new_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502939, 800)\n",
      "(8841823, 800)\n"
     ]
    }
   ],
   "source": [
    "query_new_np, passage_new_np = generate_new_np(query_np, passage_np, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Add the new numpy array to Flatindex\n",
    "import faiss\n",
    "dim = query_new_np.shape[1]\n",
    "query_index = faiss.IndexFlatIP(dim)\n",
    "query_index.add(query_new_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Find n nearest queries of a passage\n",
    "# 7. Compare with the groud truth\n",
    "def evaluate_reverse_ranker(pred_rank, true_rank, k = 100):\n",
    "    top_true = []\n",
    "    top_pred = []\n",
    "    for pid, qids in pred_rank.items():\n",
    "        n_top_true = len(true_rank.get(pid, {}))\n",
    "        temp_pred = np.fromiter(qids.values(), dtype=int)\n",
    "        n_top_pred = sum((temp_pred != 0) & (temp_pred <= k))\n",
    "        top_true.append(n_top_true)\n",
    "        top_pred.append(n_top_pred)\n",
    "    return top_true, top_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_rank(query_index, true_dict, baseline_dict, passage_embed=passage_new_np, \n",
    "                       qid_mapping=qid_mapping, pid_reverse_mapping=pid_reverse_mapping, n=100, k=100):\n",
    "    pid_list = list(baseline_dict.keys())\n",
    "    all_results = {}\n",
    "    for i, pid in enumerate(pid_list):\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "        if i >= n:\n",
    "            break\n",
    "        pid_r = pid_reverse_mapping[pid]\n",
    "        p_embed = passage_embed[pid_r]\n",
    "        _, near_qids = query_index.search(np.array([p_embed]), k)\n",
    "        temp_results = {}\n",
    "        for qid in near_qids[0]:\n",
    "            qid = qid_mapping[qid]\n",
    "            try:\n",
    "                rank = true_dict[pid][qid]\n",
    "            except:\n",
    "                rank = 0\n",
    "            temp_results[qid] = rank\n",
    "        all_results[pid] = temp_results\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RANK_PATH = \"/datadrive/jianx/data/train_data/ance_training_rank100_8841823.csv\"\n",
    "N_PASSAGE = 100\n",
    "TRAIN_PASSAGE = 200000\n",
    "def load_train(path, N_PASSAGE = 100, TRAIN_PASSAGE = 200000):\n",
    "    with open(path) as file:\n",
    "        line = file.readline()\n",
    "        my_dict = {}\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            if count >= (TRAIN_PASSAGE + N_PASSAGE) * 100:\n",
    "                break\n",
    "            count += 1\n",
    "            if count < TRAIN_PASSAGE * 100:\n",
    "                continue\n",
    "            tokens = line.split(\",\")\n",
    "            pid = int(tokens[0])\n",
    "            qid = int(tokens[1])\n",
    "            rank = int(tokens[2].rstrip())\n",
    "            if pid not in my_dict:\n",
    "                my_dict[pid] = {}\n",
    "            my_dict[pid][qid] = rank\n",
    "    return my_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_baseline(query_index, true_dict_100, forward_baseline_rank, n=500):\n",
    "    pred_rank = generate_pred_rank(query_index, true_dict_100, forward_baseline_rank, n=n)\n",
    "    top_true, top_pred = evaluate_reverse_ranker(pred_rank, true_dict_100, k = 100)\n",
    "    print(\"New model: {}\".format(np.mean(top_pred)/np.mean(top_true)))\n",
    "    top_true_baseline, top_pred_baseline = evaluate_reverse_ranker(forward_baseline_rank, true_dict_100, k = 100)\n",
    "    print(\"Baseline model: {}\".format(np.mean(top_pred_baseline)/np.mean(top_true_baseline)))\n",
    "    return top_true, top_pred, top_true_baseline, top_pred_baseline, pred_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_baseline_rank_test = load_train(TRAIN_RANK_PATH, N_PASSAGE = 500, TRAIN_PASSAGE = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "New model: 0.8812333460220785\n",
      "Baseline model: 0.8668695321414986\n"
     ]
    }
   ],
   "source": [
    "top_true_test, top_pred_test, top_true_baseline_test, top_pred_baseline_test, pred_rank_test = compare_with_baseline(query_index, true_dict_100, forward_baseline_rank_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_writer(obj, path):\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = \"/datadrive/ruohan/reverse_ranker/loss_0.12/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_baseline_rank_train = load_train(TRAIN_RANK_PATH, N_PASSAGE = 500, TRAIN_PASSAGE = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "New model: 0.8972089857045609\n",
      "Baseline model: 0.8318584070796461\n"
     ]
    }
   ],
   "source": [
    "top_true_train, top_pred_train, top_true_baseline_train, top_pred_baseline_train, pred_rank_train = compare_with_baseline(query_index, true_dict_100, forward_baseline_rank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_writer(forward_baseline_rank_test1, RESULT_PATH + \"forward_baseline_rank_test.pickle\")\n",
    "# obj_writer(top_true_test1, RESULT_PATH + \"top_true_test.pickle\")\n",
    "# obj_writer(top_pred_test1, RESULT_PATH + \"top_pred_test.pickle\")\n",
    "# obj_writer(top_true_baseline_test1, RESULT_PATH + \"top_true_baseline_test.pickle\")\n",
    "# obj_writer(top_pred_baseline_test1, RESULT_PATH + \"top_pred_baseline_test.pickle\")\n",
    "# obj_writer(pred_rank_test1, RESULT_PATH + \"pred_rank_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "5000\n",
      "5050\n",
      "5100\n",
      "5150\n",
      "5200\n",
      "5250\n",
      "5300\n",
      "5350\n",
      "5400\n",
      "5450\n",
      "5500\n",
      "5550\n",
      "5600\n",
      "5650\n",
      "5700\n",
      "5750\n",
      "5800\n",
      "5850\n",
      "5900\n",
      "5950\n",
      "6000\n",
      "6050\n",
      "6100\n",
      "6150\n",
      "6200\n",
      "6250\n",
      "6300\n",
      "6350\n",
      "6400\n",
      "6450\n",
      "6500\n",
      "6550\n",
      "6600\n",
      "6650\n",
      "6700\n",
      "6750\n",
      "6800\n",
      "6850\n",
      "6900\n",
      "6950\n",
      "7000\n",
      "7050\n",
      "7100\n",
      "7150\n",
      "7200\n",
      "7250\n",
      "7300\n",
      "7350\n",
      "7400\n",
      "7450\n",
      "7500\n",
      "7550\n",
      "7600\n",
      "7650\n",
      "7700\n",
      "7750\n",
      "7800\n",
      "7850\n",
      "7900\n",
      "7950\n",
      "8000\n",
      "8050\n",
      "8100\n",
      "8150\n",
      "8200\n",
      "8250\n",
      "8300\n",
      "8350\n",
      "8400\n",
      "8450\n",
      "8500\n",
      "8550\n",
      "8600\n",
      "8650\n",
      "8700\n",
      "8750\n",
      "8800\n",
      "8850\n",
      "8900\n",
      "8950\n",
      "9000\n",
      "9050\n",
      "9100\n",
      "9150\n",
      "9200\n",
      "9250\n",
      "9300\n",
      "9350\n",
      "9400\n",
      "9450\n",
      "9500\n",
      "9550\n",
      "9600\n",
      "9650\n",
      "9700\n",
      "9750\n",
      "9800\n",
      "9850\n",
      "9900\n",
      "9950\n",
      "10000\n",
      "New model: 0.8699718867691002\n",
      "Baseline model: 0.8510235830711028\n"
     ]
    }
   ],
   "source": [
    "forward_baseline_rank_test1 = load_train(TRAIN_RANK_PATH, N_PASSAGE = 10000, TRAIN_PASSAGE = 200000)\n",
    "top_true_test1, top_pred_test1, top_true_baseline_test1, top_pred_baseline_test1, pred_rank_test1 = compare_with_baseline(query_index, true_dict_100, forward_baseline_rank_test1,n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_writer(forward_baseline_rank_train1, RESULT_PATH + \"forward_baseline_rank_train.pickle\")\n",
    "# obj_writer(top_true_train1, RESULT_PATH + \"top_true_train.pickle\")\n",
    "# obj_writer(top_pred_train1, RESULT_PATH + \"top_pred_train.pickle\")\n",
    "# obj_writer(top_true_baseline_train1, RESULT_PATH + \"top_true_baseline_train.pickle\")\n",
    "# obj_writer(top_pred_baseline_train1, RESULT_PATH + \"top_pred_baseline_train.pickle\")\n",
    "# obj_writer(pred_rank_train1, RESULT_PATH + \"pred_rank_train.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "5000\n",
      "5050\n",
      "5100\n",
      "5150\n",
      "5200\n",
      "5250\n",
      "5300\n",
      "5350\n",
      "5400\n",
      "5450\n",
      "5500\n",
      "5550\n",
      "5600\n",
      "5650\n",
      "5700\n",
      "5750\n",
      "5800\n",
      "5850\n",
      "5900\n",
      "5950\n",
      "6000\n",
      "6050\n",
      "6100\n",
      "6150\n",
      "6200\n",
      "6250\n",
      "6300\n",
      "6350\n",
      "6400\n",
      "6450\n",
      "6500\n",
      "6550\n",
      "6600\n",
      "6650\n",
      "6700\n",
      "6750\n",
      "6800\n",
      "6850\n",
      "6900\n",
      "6950\n",
      "7000\n",
      "7050\n",
      "7100\n",
      "7150\n",
      "7200\n",
      "7250\n",
      "7300\n",
      "7350\n",
      "7400\n",
      "7450\n",
      "7500\n",
      "7550\n",
      "7600\n",
      "7650\n",
      "7700\n",
      "7750\n",
      "7800\n",
      "7850\n",
      "7900\n",
      "7950\n",
      "8000\n",
      "8050\n",
      "8100\n",
      "8150\n",
      "8200\n",
      "8250\n",
      "8300\n",
      "8350\n",
      "8400\n",
      "8450\n",
      "8500\n",
      "8550\n",
      "8600\n",
      "8650\n",
      "8700\n",
      "8750\n",
      "8800\n",
      "8850\n",
      "8900\n",
      "8950\n",
      "9000\n",
      "9050\n",
      "9100\n",
      "9150\n",
      "9200\n",
      "9250\n",
      "9300\n",
      "9350\n",
      "9400\n",
      "9450\n",
      "9500\n",
      "9550\n",
      "9600\n",
      "9650\n",
      "9700\n",
      "9750\n",
      "9800\n",
      "9850\n",
      "9900\n",
      "9950\n",
      "10000\n",
      "New model: 0.8553186055420763\n",
      "Baseline model: 0.8345837057847018\n"
     ]
    }
   ],
   "source": [
    "forward_baseline_rank_train1 = load_train(TRAIN_RANK_PATH, N_PASSAGE = 10000, TRAIN_PASSAGE = 0)\n",
    "top_true_train1, top_pred_train1, top_true_baseline_train1, top_pred_baseline_train1, pred_rank_train1 = compare_with_baseline(query_index, true_dict_100, forward_baseline_rank_train1, n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(reverse_ranker.state_dict(), \"./results/good_reverse_ranker.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 1, 3, 19, 2, 2, 3, 10, 1, 5, 10, 53, 4, 3, 12, 16, 1, 13, 2, 3]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_true_test1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 1, 3, 19, 2, 2, 3, 10, 1, 5, 10, 52, 4, 3, 9, 12, 1, 11, 2, 3]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pred_baseline_test1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 1, 3, 19, 2, 2, 3, 10, 1, 5, 8, 53, 4, 3, 10, 10, 1, 12, 2, 3]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pred_test1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 1, 1, 3, 1, 0, 9, 10, 0, 2, 12, 4, 7, 16, 8, 1, 1, 7, 18]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pred_train1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 1, 1, 3, 1, 0, 8, 8, 0, 1, 12, 4, 7, 16, 8, 1, 1, 7, 17]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pred_baseline_train1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 10, 1, 1, 3, 1, 0, 9, 10, 0, 2, 12, 4, 7, 17, 8, 1, 1, 7, 19]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_true_train1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{936936: 0, 70513: 0, 71691: 99, 71002: 52, 634337: 3, 763319: 0, 95819: 0, 65995: 0, 198927: 0, 638036: 0, 761508: 0, 416960: 0, 172447: 0, 471214: 0, 476027: 41, 77359: 0, 1022143: 0, 86942: 80, 1077609: 0, 838494: 0, 166361: 0, 84516: 0, 414158: 0, 625548: 0, 85370: 0, 70841: 0, 64183: 0, 616111: 0, 66134: 0, 761459: 0, 66463: 55, 404677: 8, 884677: 0, 168620: 0, 1070287: 0, 67585: 0, 416099: 0, 70844: 0, 415965: 71, 894492: 0, 70707: 0, 590621: 71, 772753: 0, 881550: 0, 95384: 0, 629020: 0, 565894: 0, 66470: 0, 67856: 0, 581246: 0, 70552: 0, 586461: 0, 67531: 0, 168486: 0, 65342: 0, 586843: 0, 165145: 0, 165076: 0, 67587: 0, 974184: 0, 72794: 0, 67247: 0, 54478: 0, 973060: 0, 54702: 0, 925642: 0, 1159295: 0, 70583: 0, 181081: 0, 73453: 0, 70679: 0, 584760: 0, 5992: 0, 77710: 0, 1077594: 0, 434346: 0, 439545: 0, 869829: 0, 72747: 0, 640480: 0, 70842: 0, 1004472: 0, 1171233: 0, 507385: 0, 484238: 0, 637324: 0, 581481: 0, 416205: 0, 62401: 0, 641498: 0, 741674: 0, 72569: 0, 173640: 0, 53689: 0, 894636: 0, 894487: 0, 406060: 0, 495271: 0, 462363: 0, 151433: 0}\n",
      "{71691: 99, 590621: 71, 590592: 0, 469953: 90, 586843: 0, 591227: 0, 519828: 0, 476027: 41, 495271: 0, 65992: 0, 87768: 0, 65995: 0, 586514: 0, 84218: 0, 84516: 0, 507385: 0, 172447: 0, 514839: 0, 881550: 0, 590624: 0, 66463: 55, 889671: 0, 67531: 0, 70841: 0, 472913: 0, 86921: 0, 439545: 0, 471248: 0, 86942: 80, 473624: 0, 772753: 0, 72192: 0, 601396: 0, 587963: 0, 393095: 0, 114860: 0, 585120: 0, 26948: 0, 140373: 0, 587578: 0, 1008597: 0, 97350: 0, 86318: 0, 883742: 0, 170480: 0, 86981: 0, 63547: 0, 936936: 0, 184347: 0, 581232: 0, 64945: 0, 168543: 0, 88285: 0, 1159295: 0, 67856: 0, 590556: 0, 520020: 0, 471214: 0, 590500: 0, 590530: 0, 634337: 3, 88663: 0, 585760: 0, 810322: 0, 2338: 0, 70679: 0, 601383: 0, 85487: 0, 1164188: 0, 471452: 0, 439368: 0, 63018: 0, 165549: 0, 1163760: 0, 1159099: 0, 588558: 0, 589337: 0, 11136: 0, 894492: 0, 495272: 0, 601412: 0, 899174: 0, 1164663: 0, 601327: 0, 70401: 0, 165145: 0, 590511: 0, 795406: 0, 581498: 0, 586461: 0, 140391: 0, 70615: 0, 581456: 0, 507450: 0, 73893: 0, 936957: 0, 479737: 0, 585749: 0, 72794: 0, 581348: 0}\n"
     ]
    }
   ],
   "source": [
    "pid = list(pred_rank_test1.keys())[0]\n",
    "print(pred_rank_test1[pid])\n",
    "print(forward_baseline_rank_test1[pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
