{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data: passage_embeddings, query_train_embeddings, train_data (a proportion of)\n",
    "# 2. Network input: 768 output: 32\n",
    "# 3. Train: concatenate original 768 with 32 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data: load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "PASSAGE_NP_PATH = \"/home/jianx/results/passage_0__emb_p__data_obj_0.pb\"\n",
    "PASSAGE_MAP_PATH = \"/datadrive/jianx/data/annoy/100_ance_passage_map.dict\"\n",
    "QUERY_TRAIN_NP_PATH = \"/home/jianx/results/query_0__emb_p__data_obj_0.pb\"\n",
    "QUERY_MAP_PATH = \"/datadrive/jianx/data/annoy/100_ance_query_train_map.dict\"\n",
    "TRAIN_RANK_PATH = \"/datadrive/jianx/data/train_data/ance_training_rank100_8841823.csv\"\n",
    "# TRAIN_RANK_PATH = \"/datadrive/ruohan/reverse_ranker/new_training/combine_rank_train_phase2.csv\"\n",
    "\n",
    "\n",
    "OUT_RANK = 200\n",
    "N_PASSAGE = 200000\n",
    "def obj_reader(path):\n",
    "    with open(path, 'rb') as handle:\n",
    "        return pickle.load(handle, encoding=\"bytes\")\n",
    "def load_train(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        pos_dict = {}\n",
    "        neg_dict = {}\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            if count >= N_PASSAGE * 100:\n",
    "                break\n",
    "            count += 1\n",
    "            tokens = line.split(\",\")\n",
    "            pid = int(tokens[0])\n",
    "            qid = int(tokens[1])\n",
    "            rank = int(tokens[2].rstrip())\n",
    "            if rank == 0:\n",
    "                if pid not in neg_dict:\n",
    "                    neg_dict[pid] = {}\n",
    "                neg_dict[pid][qid] = OUT_RANK\n",
    "            else:\n",
    "                if pid not in pos_dict:\n",
    "                    pos_dict[pid] = {}\n",
    "                pos_dict[pid][qid] = rank\n",
    "    return pos_dict, neg_dict\n",
    "def map_id(old_np, mapping):\n",
    "    new_dict = dict(zip(mapping.values(),old_np))\n",
    "    return new_dict\n",
    "def load():\n",
    "    print(\"Load embeddings.\")\n",
    "    passage_np = obj_reader(PASSAGE_NP_PATH)\n",
    "    pid_mapping = obj_reader(PASSAGE_MAP_PATH)\n",
    "    query_np = obj_reader(QUERY_TRAIN_NP_PATH)\n",
    "    qid_mapping = obj_reader(QUERY_MAP_PATH)\n",
    "    print(\"Mapping ids.\")\n",
    "    query_dict = map_id(query_np, qid_mapping)\n",
    "    passage_dict = map_id(passage_np, pid_mapping)\n",
    "    print(\"Load training data.\")\n",
    "    train_pos_dict, train_neg_dict = load_train(TRAIN_RANK_PATH)\n",
    "    return train_pos_dict, train_neg_dict, query_dict, passage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pos_dict, train_neg_dict = load_train(TRAIN_RANK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embeddings.\n",
      "Mapping ids.\n",
      "Load training data.\n"
     ]
    }
   ],
   "source": [
    "train_pos_dict, train_neg_dict, query_dict, passage_dict = load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture: network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_HIDDEN_NODES = 1536\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "DROPOUT_RATE = 0.1\n",
    "FEAT_COUNT = 768\n",
    "\n",
    "\n",
    "# Define the network\n",
    "class CorpusNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size):\n",
    "        super(CorpusNet, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        last_dim = FEAT_COUNT\n",
    "        for i in range(NUM_HIDDEN_LAYERS):\n",
    "            layers.append(nn.Linear(last_dim, NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.LayerNorm(NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.Dropout(p=DROPOUT_RATE))\n",
    "            last_dim = NUM_HIDDEN_NODES\n",
    "        layers.append(nn.Linear(last_dim, embed_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def parameter_count(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train reverse ranker: train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "TOP_K = 100\n",
    "\n",
    "# With probability alpha\n",
    "# Select a random negative sample from train_neg_dict\n",
    "ALPHA = 0.5\n",
    "\n",
    "def dot_product(A, B, normalize=False):\n",
    "    if normalize:\n",
    "        A = F.normalize(A)\n",
    "        B = F.normalize(B)\n",
    "    b = A.shape[0]\n",
    "    embed = A.shape[1]\n",
    "    result = torch.bmm(A.view(b, 1, embed), B.view(b, embed, 1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def mini_batch(batch_size, device, train_pos_dict, train_neg_dict, query_dict, passage_dict):\n",
    "    passage_list = list(train_neg_dict.keys())\n",
    "    passages = []\n",
    "    pos = []\n",
    "    neg = []\n",
    "    pos_rank_list = []\n",
    "    neg_rank_list = []\n",
    "    while len(passages) < batch_size:\n",
    "        pid = random.sample(passage_list, 1)[0]\n",
    "        try:\n",
    "            temp_pos_list = list(train_pos_dict[pid].keys())\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            temp_neg_list = list(train_neg_dict[pid].keys())\n",
    "        except:\n",
    "            continue\n",
    "        if np.random.uniform(0,1,1) <= ALPHA:\n",
    "            random_positive = random.sample(temp_pos_list, 1)\n",
    "            pos_qid = random_positive[0]\n",
    "            pos_rank = train_pos_dict[pid][pos_qid]\n",
    "            random_negative = random.sample(temp_neg_list, 1)\n",
    "            neg_qid = random_negative[0]\n",
    "            neg_rank = train_neg_dict[pid][neg_qid]\n",
    "#             not_negative = True\n",
    "#             while not_negative:\n",
    "#                 temp_neg_qid = random.sample(list(query_dict.keys()), 1)\n",
    "#                 if temp_neg_qid not in temp_query_list:\n",
    "#                     neg_qid = temp_neg_qid[0]\n",
    "#                     neg_rank = 1000\n",
    "#                     not_negative = False\n",
    "        else:\n",
    "            if len(temp_pos_list) < 2:\n",
    "                continue\n",
    "            pos_neg_pair = random.sample(temp_pos_list, 2)\n",
    "            # e.g. 60 >= 3\n",
    "            if train_pos_dict[pid][pos_neg_pair[0]] >= train_pos_dict[pid][pos_neg_pair[1]]:\n",
    "                pos_qid = pos_neg_pair[1]\n",
    "                neg_qid = pos_neg_pair[0]\n",
    "            # e.g. 3 < 60\n",
    "            else:\n",
    "                pos_qid = pos_neg_pair[0]\n",
    "                neg_qid = pos_neg_pair[1]   \n",
    "            pos_rank = train_pos_dict[pid][pos_qid]\n",
    "            neg_rank = train_pos_dict[pid][neg_qid]\n",
    "        p_seq = passage_dict[pid]\n",
    "        pos_seq = query_dict[pos_qid]\n",
    "        neg_seq = query_dict[neg_qid]\n",
    "        passages.append(p_seq)\n",
    "        pos.append(pos_seq)\n",
    "        neg.append(neg_seq)\n",
    "        pos_rank_list.append(TOP_K - pos_rank)\n",
    "        neg_rank_list.append(TOP_K - neg_rank)\n",
    "#         pos_rank_list.append((TOP_K - pos_rank) * 2)\n",
    "#         neg_rank_list.append((TOP_K - neg_rank) * 2)\n",
    "    labels = torch.stack([torch.FloatTensor(pos_rank_list), torch.FloatTensor(neg_rank_list)], dim=1)\n",
    "    passages = torch.from_numpy(np.stack(passages))\n",
    "    pos = torch.from_numpy(np.stack(pos))\n",
    "    neg = torch.from_numpy(np.stack(neg))\n",
    "    return passages.to(device), pos.to(device), neg.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "def train(net, epoch_size, batch_size, optimizer, device, train_pos_dict, train_neg_dict, \n",
    "          query_dict, passage_dict, scale=10, loss_option=\"ce\"):\n",
    "    bce = nn.BCELoss()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for mb_idx in range(epoch_size):\n",
    "        # Read in a new mini-batch of data!\n",
    "        passages, pos, neg, labels = mini_batch(batch_size, device, train_pos_dict, train_neg_dict, \n",
    "                                                query_dict, passage_dict)\n",
    "        optimizer.zero_grad()\n",
    "        p_embed = net(passages).to(device)\n",
    "        pos_embed = net(pos).to(device)\n",
    "        neg_embed = net(neg).to(device)\n",
    "        out_pos = dot_product(p_embed, pos_embed).to(device)\n",
    "        out_neg = dot_product(p_embed, neg_embed).to(device)\n",
    "        out = torch.cat((out_pos, out_neg), -1).squeeze()\n",
    "#         out = torch.cat((out_pos, out_neg), -1) * torch.tensor([scale], dtype=torch.float).to(device)\n",
    "#         print(softmax(out))\n",
    "#         print(labels)\n",
    "#         loss = criterion(softmax(out).squeeze(), softmax(labels))\n",
    "        if loss_option == \"bce\":\n",
    "            loss = bce(softmax(out), softmax(labels))\n",
    "        if loss_option == \"ce\":\n",
    "            loss = ce(out, torch.tensor([0 for i in range(batch_size)]).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # print(str(mb_idx) + \" iteration: \" + str(train_loss / (mb_idx + 1)))\n",
    "    return train_loss / epoch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function: main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/datadrive/ruohan/results/transformation/\"\n",
    "CURRENT_DEVICE = \"cuda:0\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "\n",
    "\n",
    "def main(num_epochs, epoch_size, batch_size, learning_rate, model_path, embed_size, pretrained=False):\n",
    "    if pretrained:\n",
    "        net = CorpusNet(embed_size=embed_size)\n",
    "        net.load_state_dict(torch.load(\"/home/ruohan/DSSM/search-exposure/reverse_ranker/results/reverse_fine_tune1000_100_1000_0.0001_32.model\"))\n",
    "        net.to(CURRENT_DEVICE)\n",
    "    else:\n",
    "        net = CorpusNet(embed_size=embed_size).to(CURRENT_DEVICE)\n",
    "    print(\"Loading data\")\n",
    "#     train_rank_dict, query_dict, passage_dict = load()\n",
    "#     print(\"Data successfully loaded.\")\n",
    "#     print(\"Positive Negative Pair dict size: \" + str(len(train_rank_dict)))\n",
    "#     print(\"Num of queries: \" + str(len(query_dict)))\n",
    "#     print(\"Num of passages: \" + str(len(passage_dict)))\n",
    "#     print(\"Finish loading.\")\n",
    "\n",
    "    arg_str = \"reverse_transformation_alpha0.5\" + str(num_epochs) + \"_\" + str(epoch_size) + \"_\" + str(batch_size) + \"_\" + str(learning_rate) + \"_\" + str(\n",
    "        embed_size)\n",
    "    unique_path = model_path + arg_str + \".model\"\n",
    "    output_path = model_path + arg_str + \".csv\"\n",
    "    for ep_idx in range(num_epochs):\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        train_loss = train(net, epoch_size, batch_size, optimizer, CURRENT_DEVICE, train_pos_dict, \n",
    "                           train_neg_dict, query_dict, passage_dict)\n",
    "        print(ep_idx,train_loss)\n",
    "        with open(output_path, mode='a+') as output:\n",
    "            output_writer = csv.writer(output)\n",
    "            output_writer.writerow([ep_idx, train_loss])\n",
    "        torch.save(net.state_dict(), unique_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "0 1.5841199100017547\n",
      "1 1.2224436140060424\n",
      "2 1.1239557188749314\n",
      "3 1.0650203430652618\n",
      "4 1.0230531549453736\n",
      "5 0.9853734505176545\n",
      "6 0.9481772208213806\n",
      "7 0.9276855325698853\n",
      "8 0.9114906793832779\n",
      "9 0.8874350064992904\n",
      "10 0.8655343216657638\n",
      "11 0.8504319810867309\n",
      "12 0.8310783970355987\n",
      "13 0.820599313378334\n",
      "14 0.7957104051113129\n",
      "15 0.7754833590984345\n",
      "16 0.7557948023080826\n",
      "17 0.7494232040643692\n",
      "18 0.7265695065259934\n",
      "19 0.701999683380127\n",
      "20 0.6834408783912659\n",
      "21 0.6537602281570435\n",
      "22 0.59505859375\n",
      "23 0.5584335029125214\n",
      "24 0.549400560259819\n",
      "25 0.5413497179746628\n",
      "26 0.5350819587707519\n",
      "27 0.5316854470968246\n",
      "28 0.5311836129426957\n",
      "29 0.5264308962225914\n",
      "30 0.5239516475796699\n",
      "31 0.5239113008975983\n",
      "32 0.522781457901001\n",
      "33 0.5175915187597275\n",
      "34 0.5154512268304825\n",
      "35 0.5161955758929253\n",
      "36 0.5155539497733116\n",
      "37 0.5120792472362519\n",
      "38 0.5121008962392807\n",
      "39 0.5114485618472099\n",
      "40 0.5107032564282418\n",
      "41 0.5064786043763161\n",
      "42 0.5065061470866203\n",
      "43 0.5040673565864563\n",
      "44 0.5028937247395515\n",
      "45 0.5042935866117477\n",
      "46 0.5015071839094162\n",
      "47 0.49883764028549193\n",
      "48 0.5013569933176041\n",
      "49 0.4990879836678505\n",
      "50 0.49806681722402574\n",
      "51 0.49706282407045366\n",
      "52 0.49158584684133527\n",
      "53 0.49351118594408033\n",
      "54 0.49311141669750214\n",
      "55 0.4964172226190567\n",
      "56 0.4935663887858391\n",
      "57 0.4907366159558296\n",
      "58 0.48906510800123215\n",
      "59 0.4897807493805885\n",
      "60 0.4857820937037468\n",
      "61 0.4888751831650734\n",
      "62 0.4845165741443634\n",
      "63 0.48524211794137956\n",
      "64 0.48710030019283296\n",
      "65 0.48652027279138566\n",
      "66 0.4829193440079689\n",
      "67 0.48257328271865846\n",
      "68 0.48319925129413605\n",
      "69 0.47723829120397565\n",
      "70 0.480292586684227\n",
      "71 0.48475083142519\n",
      "72 0.4801416113972664\n",
      "73 0.48042732566595076\n",
      "74 0.4769773378968239\n",
      "75 0.47605515390634534\n",
      "76 0.4786974674463272\n",
      "77 0.4770841321349144\n",
      "78 0.47842331558465956\n",
      "79 0.47636673420667647\n",
      "80 0.47576515763998034\n",
      "81 0.47515427827835083\n",
      "82 0.47311365872621536\n",
      "83 0.47341171592473985\n",
      "84 0.4740257588028908\n",
      "85 0.4727492332458496\n",
      "86 0.47141036719083784\n",
      "87 0.4728225412964821\n",
      "88 0.47035458236932753\n",
      "89 0.4718071603775024\n",
      "90 0.4705827584862709\n",
      "91 0.46587050646543504\n",
      "92 0.4674488252401352\n",
      "93 0.4703489562869072\n",
      "94 0.4678854504227638\n",
      "95 0.46745901614427565\n",
      "96 0.4687179383635521\n",
      "97 0.4659082418680191\n",
      "98 0.4659932228922844\n",
      "99 0.4677391090989113\n",
      "100 0.46194584280252454\n",
      "101 0.4656941956281662\n",
      "102 0.46412880837917325\n",
      "103 0.4643599331378937\n",
      "104 0.4662442058324814\n",
      "105 0.4637039640545845\n",
      "106 0.46667615711689\n",
      "107 0.46288976818323135\n",
      "108 0.46503228932619095\n",
      "109 0.46071121245622637\n",
      "110 0.4619129768013954\n",
      "111 0.45782482653856277\n",
      "112 0.45846737176179886\n",
      "113 0.45733880519866943\n",
      "114 0.4603640377521515\n",
      "115 0.4596176466345787\n",
      "116 0.45861262440681455\n",
      "117 0.4600448313355446\n",
      "118 0.45550846934318545\n",
      "119 0.45798113495111464\n",
      "120 0.4589106526970863\n",
      "121 0.4575605198740959\n",
      "122 0.45719568848609926\n",
      "123 0.45661034524440763\n",
      "124 0.45828590482473375\n",
      "125 0.45591865718364716\n",
      "126 0.45465578585863115\n",
      "127 0.4540709352493286\n",
      "128 0.45657815486192704\n",
      "129 0.45279382795095446\n",
      "130 0.455075312256813\n",
      "131 0.45202293813228606\n",
      "132 0.45404171109199526\n",
      "133 0.4535145577788353\n",
      "134 0.45343433439731595\n",
      "135 0.45241256088018417\n",
      "136 0.4534834152460098\n",
      "137 0.449495307803154\n",
      "138 0.4509690099954605\n",
      "139 0.44995467633008956\n",
      "140 0.4482760924100876\n",
      "141 0.45060596615076065\n",
      "142 0.45221896559000013\n",
      "143 0.4488049364089966\n",
      "144 0.446305870115757\n",
      "145 0.448473285138607\n",
      "146 0.446294761300087\n",
      "147 0.4476143753528595\n",
      "148 0.4488592481613159\n",
      "149 0.44898842215538026\n",
      "150 0.44851508557796477\n",
      "151 0.4452401578426361\n",
      "152 0.4444814509153366\n",
      "153 0.44694700866937637\n",
      "154 0.44687677174806595\n",
      "155 0.44868831902742384\n",
      "156 0.4466197073459625\n",
      "157 0.4469281470775604\n",
      "158 0.4465025532245636\n",
      "159 0.44470890432596205\n",
      "160 0.44724050760269163\n",
      "161 0.44494731426239015\n",
      "162 0.4429310601949692\n",
      "163 0.44354667514562607\n",
      "164 0.44671432077884676\n",
      "165 0.44476485073566435\n",
      "166 0.44421096712350844\n",
      "167 0.4467714548110962\n",
      "168 0.4415654793381691\n",
      "169 0.4421700400114059\n",
      "170 0.4438561949133873\n",
      "171 0.44199277758598327\n",
      "172 0.440423903465271\n",
      "173 0.43869033962488174\n",
      "174 0.44018561750650403\n",
      "175 0.442118943631649\n",
      "176 0.439920454621315\n",
      "177 0.4401231488585472\n",
      "178 0.4399642559885979\n",
      "179 0.43789746552705766\n",
      "180 0.4386709645390511\n",
      "181 0.4413364174962044\n",
      "182 0.43776549339294435\n",
      "183 0.440524554848671\n",
      "184 0.43742231130599973\n",
      "185 0.43853829979896547\n",
      "186 0.4409463685750961\n",
      "187 0.4362191542983055\n",
      "188 0.4378258916735649\n",
      "189 0.43694442838430403\n",
      "190 0.4376638016104698\n",
      "191 0.4356950715184212\n",
      "192 0.4329220750927925\n",
      "193 0.43504068851470945\n",
      "194 0.43346877545118334\n",
      "195 0.43731305867433545\n",
      "196 0.43752997666597365\n",
      "197 0.4353146028518677\n",
      "198 0.43448212057352065\n",
      "199 0.4328605303168297\n",
      "200 0.4338581821322441\n",
      "201 0.43291018456220626\n",
      "202 0.43115907728672026\n",
      "203 0.43273663461208345\n",
      "204 0.43043693512678144\n",
      "205 0.43245334714651107\n",
      "206 0.4325386270880699\n",
      "207 0.4341829541325569\n",
      "208 0.43204560071229936\n",
      "209 0.4345313212275505\n",
      "210 0.4318450844287872\n",
      "211 0.4293033167719841\n",
      "212 0.4320387077331543\n",
      "213 0.42985751301050185\n",
      "214 0.4310719323158264\n",
      "215 0.4319628939032555\n",
      "216 0.4313875615596771\n",
      "217 0.43049784541130065\n",
      "218 0.43030752062797545\n",
      "219 0.4292640146613121\n",
      "220 0.43158542692661284\n",
      "221 0.4278075224161148\n",
      "222 0.4288965290784836\n",
      "223 0.42761157602071764\n",
      "224 0.4329656282067299\n",
      "225 0.42980960965156556\n",
      "226 0.42847554981708524\n",
      "227 0.4290359255671501\n",
      "228 0.4256141397356987\n",
      "229 0.4265154305100441\n",
      "230 0.4298032140731812\n",
      "231 0.4249257463216782\n",
      "232 0.42848356276750565\n",
      "233 0.42516892224550246\n",
      "234 0.42881842523813246\n",
      "235 0.4276963797211647\n",
      "236 0.4252240341901779\n",
      "237 0.42599209189414977\n",
      "238 0.4225739908218384\n",
      "239 0.426862413585186\n",
      "240 0.42563833683729174\n",
      "241 0.4238662365078926\n",
      "242 0.4226746717095375\n",
      "243 0.42717248141765596\n",
      "244 0.4234672683477402\n",
      "245 0.42295278966426847\n",
      "246 0.4253518345952034\n",
      "247 0.4190322530269623\n",
      "248 0.42551137149333956\n",
      "249 0.4222381138801575\n",
      "250 0.4256630477309227\n",
      "251 0.4256054240465164\n",
      "252 0.42258654832839965\n",
      "253 0.42224124521017076\n",
      "254 0.42377889543771746\n",
      "255 0.4192979630827904\n",
      "256 0.42019864797592166\n",
      "257 0.42167025685310366\n",
      "258 0.41779481500387194\n",
      "259 0.41791256219148637\n",
      "260 0.4205146199464798\n",
      "261 0.4186283975839615\n",
      "262 0.41970238715410235\n",
      "263 0.4185332372784615\n",
      "264 0.4210616651177406\n",
      "265 0.42138698369264604\n",
      "266 0.4182197517156601\n",
      "267 0.4188634577393532\n",
      "268 0.4170550167560577\n",
      "269 0.41930313915014267\n",
      "270 0.4179625114798546\n",
      "271 0.41778505831956864\n",
      "272 0.4154804736375809\n",
      "273 0.4184694501757622\n",
      "274 0.42031519800424577\n",
      "275 0.41942188203334807\n",
      "276 0.4139946520328522\n",
      "277 0.4161770507693291\n",
      "278 0.4188016140460968\n",
      "279 0.41569600701332093\n",
      "280 0.4189058995246887\n",
      "281 0.41722620636224744\n",
      "282 0.41401194751262665\n",
      "283 0.41713947176933286\n",
      "284 0.4153343862295151\n",
      "285 0.41670104682445525\n",
      "286 0.41450162589550016\n",
      "287 0.4160128226876259\n",
      "288 0.41041227638721467\n",
      "289 0.4132542032003403\n",
      "290 0.41874918788671495\n",
      "291 0.41236152917146685\n",
      "292 0.41361076980829237\n",
      "293 0.4135542577505112\n",
      "294 0.41604157477617265\n",
      "295 0.4113011085987091\n",
      "296 0.41236724525690077\n",
      "297 0.41157871842384336\n",
      "298 0.410113559961319\n",
      "299 0.4126923459768295\n",
      "300 0.4115282294154167\n",
      "301 0.4150109526515007\n",
      "302 0.4137237754464149\n",
      "303 0.41332564562559126\n",
      "304 0.4116122394800186\n",
      "305 0.41336932390928266\n",
      "306 0.40923592537641523\n",
      "307 0.4108522841334343\n",
      "308 0.4090059232711792\n",
      "309 0.40881363064050674\n",
      "310 0.41432752311229704\n",
      "311 0.4105182647705078\n",
      "312 0.40629440754652024\n",
      "313 0.40678799748420713\n",
      "314 0.40961836397647855\n",
      "315 0.4102597573399544\n",
      "316 0.4086763074994087\n",
      "317 0.40825396686792376\n",
      "318 0.40706530809402464\n",
      "319 0.4065994539856911\n",
      "320 0.41002015918493273\n",
      "321 0.4086058157682419\n",
      "322 0.4090434074401855\n",
      "323 0.40905830413103106\n",
      "324 0.40825500756502153\n",
      "325 0.4085292327404022\n",
      "326 0.4050049152970314\n",
      "327 0.4073824280500412\n",
      "328 0.40712554574012755\n",
      "329 0.40737623900175096\n",
      "330 0.4047380316257477\n",
      "331 0.40742233753204343\n",
      "332 0.40757947564125063\n",
      "333 0.40824332922697065\n",
      "334 0.40272013783454896\n",
      "335 0.4016602885723114\n",
      "336 0.40397641897201536\n",
      "337 0.40503408908843996\n",
      "338 0.4035238936543465\n",
      "339 0.40473135739564897\n",
      "340 0.4048807489871979\n",
      "341 0.4018624746799469\n",
      "342 0.40504785925149916\n",
      "343 0.402587548494339\n",
      "344 0.4000894340872765\n",
      "345 0.40385000020265577\n",
      "346 0.40418539732694625\n",
      "347 0.40220473080873487\n",
      "348 0.39945730805397034\n",
      "349 0.40551399052143094\n",
      "350 0.4012183156609535\n",
      "351 0.4017008835077286\n",
      "352 0.3989513504505158\n",
      "353 0.40151341050863265\n",
      "354 0.401150683760643\n",
      "355 0.4020901390910149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 0.4020874750614166\n",
      "357 0.3999578863382339\n",
      "358 0.3975589391589165\n",
      "359 0.3988784793019295\n",
      "360 0.400655078291893\n",
      "361 0.3994387823343277\n",
      "362 0.39858532905578614\n",
      "363 0.4002086138725281\n",
      "364 0.39793529838323594\n",
      "365 0.3989852511882782\n",
      "366 0.4001371932029724\n",
      "367 0.39970969140529633\n",
      "368 0.3994301795959473\n",
      "369 0.39590361624956133\n",
      "370 0.3968467849493027\n",
      "371 0.39943049877882003\n",
      "372 0.39888779193162915\n",
      "373 0.3977742424607277\n",
      "374 0.39698962181806563\n",
      "375 0.3956724187731743\n",
      "376 0.3981036850810051\n",
      "377 0.3959819310903549\n",
      "378 0.3951424723863602\n",
      "379 0.3954252102971077\n",
      "380 0.3981539922952652\n",
      "381 0.3928555351495743\n",
      "382 0.395290738940239\n",
      "383 0.3944598540663719\n",
      "384 0.3972181913256645\n",
      "385 0.3946239671111107\n",
      "386 0.39692767947912216\n",
      "387 0.39642723083496095\n",
      "388 0.3951587095856667\n",
      "389 0.3930241709947586\n",
      "390 0.3920138227939606\n",
      "391 0.39363288044929506\n",
      "392 0.39314539819955824\n",
      "393 0.39108975619077685\n",
      "394 0.39407961785793305\n",
      "395 0.3917383563518524\n",
      "396 0.3932772585749626\n",
      "397 0.39201695680618287\n",
      "398 0.3952228465676308\n",
      "399 0.39220283448696136\n",
      "400 0.39239288330078126\n",
      "401 0.39124266475439073\n",
      "402 0.3941567459702492\n",
      "403 0.3941462540626526\n",
      "404 0.39153310596942903\n",
      "405 0.39331862777471543\n",
      "406 0.3922716876864433\n",
      "407 0.3913156533241272\n",
      "408 0.39314479887485504\n",
      "409 0.3911345198750496\n",
      "410 0.390782328248024\n",
      "411 0.39291026562452314\n",
      "412 0.39136513620615004\n",
      "413 0.3894454026222229\n",
      "414 0.38712425887584684\n",
      "415 0.3914611944556236\n",
      "416 0.38837486296892165\n",
      "417 0.390132474899292\n",
      "418 0.3847974494099617\n",
      "419 0.38653249680995944\n",
      "420 0.38881698220968247\n",
      "421 0.3871468636393547\n",
      "422 0.38702800035476687\n",
      "423 0.3903657084703445\n",
      "424 0.3860233372449875\n",
      "425 0.3883230572938919\n",
      "426 0.38825915843248365\n",
      "427 0.3847449913620949\n",
      "428 0.388419106900692\n",
      "429 0.3870777770876884\n",
      "430 0.3867612466216087\n",
      "431 0.38754874885082247\n",
      "432 0.3864652279019356\n",
      "433 0.38398161172866824\n",
      "434 0.3848930570483208\n",
      "435 0.383116514980793\n",
      "436 0.3851211306452751\n",
      "437 0.38532881051301954\n",
      "438 0.38518396109342573\n",
      "439 0.38359856128692627\n",
      "440 0.3846586185693741\n",
      "441 0.385905396938324\n",
      "442 0.3835747513175011\n",
      "443 0.38148326605558397\n",
      "444 0.3824820950627327\n",
      "445 0.38549272805452345\n",
      "446 0.3846434286236763\n",
      "447 0.38756861418485644\n",
      "448 0.3813296374678612\n",
      "449 0.38093717068433763\n",
      "450 0.38272451132535934\n",
      "451 0.37860160261392595\n",
      "452 0.3814627006649971\n",
      "453 0.38125167042016983\n",
      "454 0.37860323816537855\n",
      "455 0.3826474088430405\n",
      "456 0.3811726707220078\n",
      "457 0.3804112082719803\n",
      "458 0.38184909254312516\n",
      "459 0.38174419790506364\n",
      "460 0.38120669305324556\n",
      "461 0.3821572577953339\n",
      "462 0.3783937940001488\n",
      "463 0.3810702860355377\n",
      "464 0.3772674292325974\n",
      "465 0.38092568844556807\n",
      "466 0.37721780836582186\n",
      "467 0.37980057269334794\n",
      "468 0.3785995280742645\n",
      "469 0.37842932522296907\n",
      "470 0.3827179384231567\n",
      "471 0.3788997435569763\n",
      "472 0.37739458709955215\n",
      "473 0.3786551812291145\n",
      "474 0.38222543865442277\n",
      "475 0.37821854174137115\n",
      "476 0.37964680314064025\n",
      "477 0.379296178817749\n",
      "478 0.37779277116060256\n",
      "479 0.3800579819083214\n",
      "480 0.37957449674606325\n",
      "481 0.37881860971450804\n",
      "482 0.3777484396100044\n",
      "483 0.37611849725246427\n",
      "484 0.37596195995807646\n",
      "485 0.3791759327054024\n",
      "486 0.37522211849689485\n",
      "487 0.3768823203444481\n",
      "488 0.37398257583379746\n",
      "489 0.3767255914211273\n",
      "490 0.3729302448034286\n",
      "491 0.37248422563076017\n",
      "492 0.37752706050872803\n",
      "493 0.3733742192387581\n",
      "494 0.3730186912417412\n",
      "495 0.37155490309000017\n",
      "496 0.376354121863842\n",
      "497 0.3753345176577568\n",
      "498 0.3756226149201393\n",
      "499 0.37141604036092757\n",
      "500 0.3779009440541267\n",
      "501 0.3740252786874771\n",
      "502 0.3750316244363785\n",
      "503 0.3729525646567345\n",
      "504 0.3773724666237831\n",
      "505 0.37212513625621796\n",
      "506 0.3707785087823868\n",
      "507 0.37248590886592864\n",
      "508 0.37347722113132475\n",
      "509 0.37271019697189334\n",
      "510 0.37220233887434007\n",
      "511 0.3708020570874214\n",
      "512 0.3698677200078964\n",
      "513 0.3712692540884018\n",
      "514 0.37066198855638505\n",
      "515 0.3719422954320908\n",
      "516 0.3700703772902489\n",
      "517 0.3703234902024269\n",
      "518 0.3718584081530571\n",
      "519 0.37339500457048413\n",
      "520 0.36977786958217623\n",
      "521 0.3683531004190445\n",
      "522 0.37381778061389925\n",
      "523 0.37072118520736697\n",
      "524 0.3685398316383362\n",
      "525 0.36910518765449524\n",
      "526 0.36841920733451844\n",
      "527 0.3714174383878708\n",
      "528 0.36900735557079317\n",
      "529 0.37073776721954343\n",
      "530 0.36941087782382964\n",
      "531 0.36832178473472593\n",
      "532 0.36664727360010146\n",
      "533 0.3659664100408554\n",
      "534 0.3674026381969452\n",
      "535 0.365855937898159\n",
      "536 0.3673964637517929\n",
      "537 0.36761077046394347\n",
      "538 0.3653679922223091\n",
      "539 0.36632936030626295\n",
      "540 0.3639007729291916\n",
      "541 0.3663600328564644\n",
      "542 0.3646970236301422\n",
      "543 0.3683969610929489\n",
      "544 0.36856226742267606\n",
      "545 0.36801517993211746\n",
      "546 0.36622221052646636\n",
      "547 0.36839138984680175\n",
      "548 0.36633614093065264\n",
      "549 0.36761781841516494\n",
      "550 0.3682760429382324\n",
      "551 0.3657509934902191\n",
      "552 0.36357418656349183\n",
      "553 0.3639684119820595\n",
      "554 0.36546912461519243\n",
      "555 0.3655607783794403\n",
      "556 0.36482452422380446\n",
      "557 0.36463893711566925\n",
      "558 0.36647687792778016\n",
      "559 0.36427959412336347\n",
      "560 0.3634053653478622\n",
      "561 0.36077149093151095\n",
      "562 0.36226963102817533\n",
      "563 0.36471264153718946\n",
      "564 0.3637869304418564\n",
      "565 0.3637934386730194\n",
      "566 0.3603875654935837\n",
      "567 0.3640735104680061\n",
      "568 0.36134022027254104\n",
      "569 0.36412942260503767\n",
      "570 0.36114725708961487\n",
      "571 0.36193072110414504\n",
      "572 0.3631309953331947\n",
      "573 0.3617996796965599\n",
      "574 0.3612552261352539\n",
      "575 0.3592473468184471\n",
      "576 0.3562949886918068\n",
      "577 0.3593249675631523\n",
      "578 0.36043821543455123\n",
      "579 0.3616969335079193\n",
      "580 0.36079361438751223\n",
      "581 0.3561545807123184\n",
      "582 0.35822834610939025\n",
      "583 0.3575506469607353\n",
      "584 0.3618819370865822\n",
      "585 0.3606231144070625\n",
      "586 0.359340743124485\n",
      "587 0.35822150379419326\n",
      "588 0.3610416334867477\n",
      "589 0.3605352583527565\n",
      "590 0.3600789675116539\n",
      "591 0.35828364729881285\n",
      "592 0.35987712383270265\n",
      "593 0.36207833647727966\n",
      "594 0.35909215480089185\n",
      "595 0.3571908801794052\n",
      "596 0.35814435720443727\n",
      "597 0.3566886508464813\n",
      "598 0.35963762253522874\n",
      "599 0.35588962972164156\n",
      "600 0.3560283097624779\n",
      "601 0.3576325798034668\n",
      "602 0.35614371865987776\n",
      "603 0.35920238435268403\n",
      "604 0.35737124890089034\n",
      "605 0.3557691910862923\n",
      "606 0.3592981845140457\n",
      "607 0.3584471541643143\n",
      "608 0.3590998122096062\n",
      "609 0.356471326649189\n",
      "610 0.3570117601752281\n",
      "611 0.3559288090467453\n",
      "612 0.3550679108500481\n",
      "613 0.3576644825935364\n",
      "614 0.35541709303855895\n",
      "615 0.35526669919490816\n",
      "616 0.3562338298559189\n",
      "617 0.3559631073474884\n",
      "618 0.35878741860389707\n",
      "619 0.3557929712533951\n",
      "620 0.3519392678141594\n",
      "621 0.3538048213720322\n",
      "622 0.35498925745487214\n",
      "623 0.35135051935911177\n",
      "624 0.3542958152294159\n",
      "625 0.35431573003530503\n",
      "626 0.34977936804294585\n",
      "627 0.3547105577588081\n",
      "628 0.3530172884464264\n",
      "629 0.3524674826860428\n",
      "630 0.35709751158952713\n",
      "631 0.35238892018795015\n",
      "632 0.3516458371281624\n",
      "633 0.35279298037290574\n",
      "634 0.3548025327920914\n",
      "635 0.351394479572773\n",
      "636 0.35505601614713667\n",
      "637 0.3520707121491432\n",
      "638 0.3506692826747894\n",
      "639 0.35243806421756746\n",
      "640 0.3505659395456314\n",
      "641 0.35311145812273026\n",
      "642 0.3526972806453705\n",
      "643 0.35081914663314817\n",
      "644 0.35054062873125075\n",
      "645 0.34881701797246933\n",
      "646 0.35134743809700014\n",
      "647 0.35016739755868914\n",
      "648 0.3518095636367798\n",
      "649 0.3509359383583069\n",
      "650 0.3503326240181923\n",
      "651 0.3531173384189606\n",
      "652 0.353602819442749\n",
      "653 0.35140911370515826\n",
      "654 0.34971144258975984\n",
      "655 0.35022169291973115\n",
      "656 0.34964126974344256\n",
      "657 0.3497744116187096\n",
      "658 0.35082547724246976\n",
      "659 0.34943108648061755\n",
      "660 0.35078316390514375\n",
      "661 0.3470661681890488\n",
      "662 0.34784889936447144\n",
      "663 0.34570562452077863\n",
      "664 0.3490525409579277\n",
      "665 0.34982718527317047\n",
      "666 0.3477827051281929\n",
      "667 0.34722934365272523\n",
      "668 0.34806826114654543\n",
      "669 0.3452311098575592\n",
      "670 0.3474072277545929\n",
      "671 0.3470445093512535\n",
      "672 0.3453292241692543\n",
      "673 0.34610902070999144\n",
      "674 0.3459718307852745\n",
      "675 0.3467019826173782\n",
      "676 0.34776983052492144\n",
      "677 0.347056705057621\n",
      "678 0.3499111661314964\n",
      "679 0.347104454934597\n",
      "680 0.3446449643373489\n",
      "681 0.3448784098029137\n",
      "682 0.34426709443330766\n",
      "683 0.343671535551548\n",
      "684 0.3459777882695198\n",
      "685 0.34619172155857086\n",
      "686 0.3442540791630745\n",
      "687 0.34760976403951643\n",
      "688 0.3484527239203453\n",
      "689 0.3422715690732002\n",
      "690 0.34522698253393175\n",
      "691 0.34674418658018114\n",
      "692 0.3458255860209465\n",
      "693 0.3441721218824387\n",
      "694 0.34396693617105484\n",
      "695 0.34310893416404725\n",
      "696 0.3452042379975319\n",
      "697 0.34462945520877836\n",
      "698 0.34350005596876143\n",
      "699 0.343037751019001\n",
      "700 0.3424722155928612\n",
      "701 0.34363860249519346\n",
      "702 0.3398638653755188\n",
      "703 0.34304880142211913\n",
      "704 0.34295849412679674\n",
      "705 0.3410773655772209\n",
      "706 0.34159926533699037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707 0.3451260855793953\n",
      "708 0.3452274280786514\n",
      "709 0.34324182480573656\n",
      "710 0.34428752064704893\n",
      "711 0.34053148061037064\n",
      "712 0.34447680830955507\n",
      "713 0.34175893276929853\n",
      "714 0.3428250840306282\n",
      "715 0.34347822576761244\n",
      "716 0.34309678345918654\n",
      "717 0.3404114171862602\n",
      "718 0.3401599684357643\n",
      "719 0.3412065124511719\n",
      "720 0.34410092890262606\n",
      "721 0.3419762387871742\n",
      "722 0.3402620804309845\n",
      "723 0.341599662899971\n",
      "724 0.3409479346871376\n",
      "725 0.33753475546836853\n",
      "726 0.34021723389625547\n",
      "727 0.33897086352109906\n",
      "728 0.3395370337367058\n",
      "729 0.3401792931556702\n",
      "730 0.3419737759232521\n",
      "731 0.3394516581296921\n",
      "732 0.33821287006139755\n",
      "733 0.3402704209089279\n",
      "734 0.3408271783590317\n",
      "735 0.3419508385658264\n",
      "736 0.33993827998638154\n",
      "737 0.3366083163022995\n",
      "738 0.3377618628740311\n",
      "739 0.3408259290456772\n",
      "740 0.3410904538631439\n",
      "741 0.33955041229724886\n",
      "742 0.3373316180706024\n",
      "743 0.3372531354427338\n",
      "744 0.33591152310371397\n",
      "745 0.335827451646328\n",
      "746 0.33843241691589354\n",
      "747 0.33583991587162015\n",
      "748 0.3362657940387726\n",
      "749 0.33601698726415635\n",
      "750 0.3379592537879944\n",
      "751 0.3381142497062683\n",
      "752 0.3356677779555321\n",
      "753 0.33800522595643995\n",
      "754 0.338938305079937\n",
      "755 0.3376867780089378\n",
      "756 0.3401092919707298\n",
      "757 0.33721251726150514\n",
      "758 0.33739167004823684\n",
      "759 0.3379035884141922\n",
      "760 0.3344909083843231\n",
      "761 0.33475269585847856\n",
      "762 0.3367709296941757\n",
      "763 0.33735902935266493\n",
      "764 0.3362457838654518\n",
      "765 0.33363554149866104\n",
      "766 0.33733896911144257\n",
      "767 0.3374802058935165\n",
      "768 0.3347851139307022\n",
      "769 0.3362380227446556\n",
      "770 0.33597561687231065\n",
      "771 0.33573075652122497\n",
      "772 0.3343868315219879\n",
      "773 0.33549346357584\n",
      "774 0.33418926894664763\n",
      "775 0.3348575896024704\n",
      "776 0.3354135450720787\n",
      "777 0.33698702454566953\n",
      "778 0.33574635952711107\n",
      "779 0.33560544937849046\n",
      "780 0.33667031943798065\n",
      "781 0.3320243611931801\n",
      "782 0.33504203736782073\n",
      "783 0.3326848688721657\n",
      "784 0.33698632687330243\n",
      "785 0.3318927589058876\n",
      "786 0.33500399738550185\n",
      "787 0.33539707273244856\n",
      "788 0.3334038707613945\n",
      "789 0.33170213133096693\n",
      "790 0.33751550018787385\n",
      "791 0.3315891095995903\n",
      "792 0.33262119710445404\n",
      "793 0.3339964324235916\n",
      "794 0.3345749229192734\n",
      "795 0.33681532710790635\n",
      "796 0.33520067811012266\n",
      "797 0.33481112092733384\n",
      "798 0.33474240958690643\n",
      "799 0.33242593467235565\n",
      "800 0.3336898148059845\n",
      "801 0.3310835742950439\n",
      "802 0.3336683848500252\n",
      "803 0.3333402040600777\n",
      "804 0.3308329266309738\n",
      "805 0.3340716564655304\n",
      "806 0.3307188683748245\n",
      "807 0.3310007908940315\n",
      "808 0.33375724881887436\n",
      "809 0.33114268004894254\n",
      "810 0.3323690104484558\n",
      "811 0.33105389177799227\n",
      "812 0.3295885559916496\n",
      "813 0.33110442876815793\n",
      "814 0.3271667444705963\n",
      "815 0.3288037931919098\n",
      "816 0.3304962503910065\n",
      "817 0.3286915519833565\n",
      "818 0.332288438975811\n",
      "819 0.3320611447095871\n",
      "820 0.33358971774578094\n",
      "821 0.3287549892067909\n",
      "822 0.3311778825521469\n",
      "823 0.3313711330294609\n",
      "824 0.33351781219244003\n",
      "825 0.3282995238900185\n",
      "826 0.33000134855508806\n",
      "827 0.328408784866333\n",
      "828 0.3297401514649391\n",
      "829 0.32880729287862775\n",
      "830 0.32955762594938276\n",
      "831 0.32556715816259385\n",
      "832 0.33082571685314177\n",
      "833 0.32850849628448486\n",
      "834 0.32934955298900603\n",
      "835 0.32908855319023134\n",
      "836 0.3297828328609467\n",
      "837 0.329839029610157\n",
      "838 0.32831487894058226\n",
      "839 0.32808974146842956\n",
      "840 0.3280435252189636\n",
      "841 0.32699089765548706\n",
      "842 0.32982487708330155\n",
      "843 0.33132482051849366\n",
      "844 0.32495523065328596\n",
      "845 0.33033830344676973\n",
      "846 0.3281645879149437\n",
      "847 0.3285283848643303\n",
      "848 0.32529534101486207\n",
      "849 0.3315283244848251\n",
      "850 0.3279519367218018\n",
      "851 0.33003303557634356\n",
      "852 0.3273857268691063\n",
      "853 0.3262961006164551\n",
      "854 0.3265607246756554\n",
      "855 0.32308770626783373\n",
      "856 0.3269952791929245\n",
      "857 0.32617411881685254\n",
      "858 0.3287269425392151\n",
      "859 0.3250601643323898\n",
      "860 0.3241876322031021\n",
      "861 0.32578213334083556\n",
      "862 0.3243007731437683\n",
      "863 0.32598195374011996\n",
      "864 0.3274712339043617\n",
      "865 0.32530862867832183\n",
      "866 0.32560823142528533\n",
      "867 0.3312764036655426\n",
      "868 0.3263516208529472\n",
      "869 0.32664610773324965\n",
      "870 0.327727202475071\n",
      "871 0.3275029373168945\n",
      "872 0.32424072176218033\n",
      "873 0.3240971502661705\n",
      "874 0.3235816615819931\n",
      "875 0.32411961019039154\n",
      "876 0.32710042923688887\n",
      "877 0.3260872274637222\n",
      "878 0.325872475206852\n",
      "879 0.3257341206073761\n",
      "880 0.32602533310651777\n",
      "881 0.3261749663949013\n",
      "882 0.3267416945099831\n",
      "883 0.3238317358493805\n",
      "884 0.3231573694944382\n",
      "885 0.32636491268873213\n",
      "886 0.3236924770474434\n",
      "887 0.3242947092652321\n",
      "888 0.323829807639122\n",
      "889 0.3220421224832535\n",
      "890 0.3238398313522339\n",
      "891 0.3241910594701767\n",
      "892 0.3268090808391571\n",
      "893 0.3246056047081947\n",
      "894 0.3260314166545868\n",
      "895 0.32248384147882464\n",
      "896 0.32209067285060883\n",
      "897 0.32517474710941313\n",
      "898 0.3219866180419922\n",
      "899 0.32350222021341324\n",
      "900 0.32151649296283724\n",
      "901 0.3236637780070305\n",
      "902 0.32284153908491137\n",
      "903 0.3243443754315376\n",
      "904 0.32089674592018125\n",
      "905 0.32387516856193543\n",
      "906 0.3245999988913536\n",
      "907 0.3196822267770767\n",
      "908 0.32520379245281217\n",
      "909 0.32222819536924363\n",
      "910 0.32167516589164735\n",
      "911 0.32128839641809465\n",
      "912 0.3231127870082855\n",
      "913 0.3231675776839256\n",
      "914 0.32174579352140426\n",
      "915 0.3247231757640839\n",
      "916 0.32431842654943466\n",
      "917 0.3232420375943184\n",
      "918 0.3234411570429802\n",
      "919 0.3226848462224007\n",
      "920 0.32271011531352994\n",
      "921 0.3234361127018929\n",
      "922 0.3171309620141983\n",
      "923 0.3231602954864502\n",
      "924 0.32054760336875915\n",
      "925 0.3230722525715828\n",
      "926 0.3230012345314026\n",
      "927 0.3211163783073425\n",
      "928 0.3197933125495911\n",
      "929 0.31990253627300264\n",
      "930 0.3203443145751953\n",
      "931 0.3213277080655098\n",
      "932 0.32008955866098404\n",
      "933 0.32210626840591433\n",
      "934 0.3195050963759422\n",
      "935 0.31825000286102295\n",
      "936 0.3213351169228554\n",
      "937 0.31938941866159437\n",
      "938 0.3187320753931999\n",
      "939 0.3229914590716362\n",
      "940 0.3189047116041184\n",
      "941 0.3228134915232658\n",
      "942 0.3209770104289055\n",
      "943 0.31771785020828247\n",
      "944 0.3211177009344101\n",
      "945 0.3189322516322136\n",
      "946 0.3206458321213722\n",
      "947 0.3198565763235092\n",
      "948 0.31603120774030685\n",
      "949 0.3176918378472328\n",
      "950 0.3179060599207878\n",
      "951 0.31902037709951403\n",
      "952 0.3167362466454506\n",
      "953 0.31510911345481873\n",
      "954 0.31741095036268235\n",
      "955 0.3206237435340881\n",
      "956 0.3211022412776947\n",
      "957 0.3177119213342667\n",
      "958 0.31988617599010466\n",
      "959 0.3207147368788719\n",
      "960 0.3197453537583351\n",
      "961 0.31664541125297546\n",
      "962 0.32094720512628555\n",
      "963 0.31676900535821917\n",
      "964 0.31882559061050414\n",
      "965 0.3160224437713623\n",
      "966 0.31740683048963547\n",
      "967 0.3166172966361046\n",
      "968 0.3174464246630669\n",
      "969 0.3175081899762154\n",
      "970 0.32015906274318695\n",
      "971 0.3191862580180168\n",
      "972 0.31977183640003204\n",
      "973 0.3186656951904297\n",
      "974 0.3168969738483429\n",
      "975 0.31962012201547624\n",
      "976 0.32016999065876006\n",
      "977 0.3140658915042877\n",
      "978 0.3151653170585632\n",
      "979 0.31867593079805373\n",
      "980 0.3166530480980873\n",
      "981 0.31787374675273894\n",
      "982 0.3178464978933334\n",
      "983 0.3195886954665184\n",
      "984 0.3165001294016838\n",
      "985 0.31796609729528424\n",
      "986 0.3145178338885307\n",
      "987 0.31465403765439987\n",
      "988 0.31759320080280307\n",
      "989 0.3146546745300293\n",
      "990 0.31820455968379974\n",
      "991 0.31608262985944746\n",
      "992 0.3173548942804337\n",
      "993 0.3159205210208893\n",
      "994 0.31760335475206375\n",
      "995 0.3162592202425003\n",
      "996 0.31883990138769147\n",
      "997 0.3159871065616608\n",
      "998 0.31597685396671293\n",
      "999 0.31603909492492677\n"
     ]
    }
   ],
   "source": [
    "# Phase 2 training on new training data based on 10000 passages\n",
    "main(1000,100,1000,0.0001,MODEL_PATH,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
