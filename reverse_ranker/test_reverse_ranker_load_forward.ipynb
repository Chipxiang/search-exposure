{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reverse_query_index, reverse ranker\n",
    "# Find subset of passages that are not in train set: take the first 100 of them\n",
    "# For each passage, use reverse_query_index to find top 1000 nearest queries\n",
    "# Load forward_passage_index, forward ranker\n",
    "# Use forward_passage_index to find top k passages for each of the query, count += 1 if the passage is in top k\n",
    "# Record the # of top k queries for each document \n",
    "# Plot histogram for distribution and compute the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.insert(0, '/home/jianx/search-exposure/forward_ranker/')\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from train import generate_sparse\n",
    "from load_data import obj_reader, obj_writer\n",
    "import network\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from utils import print_message\n",
    "\n",
    "EMBED_SIZE = 256\n",
    "DEVICE = \"cuda:1\"\n",
    "n_passage = 10000\n",
    "n_query = 100\n",
    "rank = 100\n",
    "\n",
    "REVERSE_INDEX_PATH = \"./results/128load_forward_query_index.ann\"\n",
    "REVERSE_RANKER_PATH = \"./results/reverse_load_forward200_50_500_0.001_256_10.model\"\n",
    "FORWARD_INDEX_PATH = \"/home/jianx/data/annoy/128_passage_index.ann\"\n",
    "FORWARD_RANKER_PATH = \"/home/jianx/data/results/100_1000_1000_0.001_256_10.model\"\n",
    "PASSAGE_DICT_PATH = \"/home/jianx/data/passages.dict\"\n",
    "QUERY_TRAIN_DICT_PATH = \"/home/jianx/data/queries_train.dict\"\n",
    "TRAIN_RANK_PATH = \"/home/jianx/data/train_data/256_20000_100_100_training.csv\"\n",
    "REVERSE_MAP_PATH = \"./results/128load_forward_qid_map.dict\"\n",
    "FORWARD_MAP_PATH = \"/home/jianx/data/annoy/128_pid_map.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    with open(path) as file:\n",
    "        line = file.readline()\n",
    "        my_dict = {}\n",
    "        while line:\n",
    "            tokens = line.split(\",\")\n",
    "            pid = int(tokens[0])\n",
    "            qid = int(tokens[1])\n",
    "            rank = int(tokens[2].rstrip())\n",
    "            if pid not in my_dict:\n",
    "                my_dict[pid] = {}\n",
    "            my_dict[pid][qid] = rank\n",
    "            line = file.readline()\n",
    "    return my_dict\n",
    "def load():\n",
    "    query_dict = obj_reader(QUERY_TRAIN_DICT_PATH)\n",
    "    passage_dict = obj_reader(PASSAGE_DICT_PATH)\n",
    "    train_rank_dict = load_train(TRAIN_RANK_PATH)\n",
    "    return train_rank_dict, query_dict, passage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "NUM_HIDDEN_NODES = 512\n",
    "NUM_HIDDEN_LAYERS = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "FEAT_COUNT = 256\n",
    "\n",
    "\n",
    "# Define the network\n",
    "class DSSM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size):\n",
    "        super(DSSM, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        last_dim = FEAT_COUNT\n",
    "        for i in range(NUM_HIDDEN_LAYERS):\n",
    "            layers.append(nn.Linear(last_dim, NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.LayerNorm(NUM_HIDDEN_NODES))\n",
    "            layers.append(nn.Dropout(p=DROPOUT_RATE))\n",
    "            last_dim = NUM_HIDDEN_NODES\n",
    "        layers.append(nn.Linear(last_dim, embed_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def parameter_count(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reverse query index\n",
    "reverse_query_index = AnnoyIndex(EMBED_SIZE, 'euclidean')\n",
    "reverse_query_index.load(REVERSE_INDEX_PATH)\n",
    "# Load reverse query index mapping dict\n",
    "reverse_query_map = obj_reader(REVERSE_MAP_PATH)\n",
    "# Load reverse ranker model\n",
    "reverse_ranker = DSSM(embed_size=EMBED_SIZE)\n",
    "reverse_ranker.load_state_dict(torch.load(REVERSE_RANKER_PATH))\n",
    "reverse_ranker.to(DEVICE)\n",
    "reverse_ranker.eval()\n",
    "# Load forward passage index\n",
    "forward_passage_index = AnnoyIndex(EMBED_SIZE, 'euclidean')\n",
    "forward_passage_index.load(FORWARD_INDEX_PATH)\n",
    "# Load forward passage index mapping dict \n",
    "forward_passage_map = obj_reader(FORWARD_MAP_PATH)\n",
    "# Load forward ranker model\n",
    "forward_ranker = network.DSSM(embed_size=EMBED_SIZE)\n",
    "forward_ranker.load_state_dict(torch.load(FORWARD_RANKER_PATH))\n",
    "forward_ranker.to(DEVICE)\n",
    "forward_ranker.eval()\n",
    "# Load train_rank, query, passage dict\n",
    "train_rank_dict, query_dict, passage_dict = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find subset of passages that are not in train set: take the first 100 of them\n",
    "train_passage_list = set(list(train_rank_dict.keys()))\n",
    "all_passage_list = set(list(passage_dict.keys()))\n",
    "test_passage_list = list(all_passage_list.difference(train_passage_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 16, 18:09:46] Processing passage No. 1/10000\n",
      "2\n",
      "[Jul 16, 18:09:47] Processing passage No. 2/10000\n",
      "1\n",
      "[Jul 16, 18:09:48] Processing passage No. 3/10000\n",
      "0\n",
      "[Jul 16, 18:09:49] Processing passage No. 4/10000\n",
      "2\n",
      "[Jul 16, 18:09:50] Processing passage No. 5/10000\n",
      "62\n",
      "[Jul 16, 18:09:51] Processing passage No. 6/10000\n",
      "2\n",
      "[Jul 16, 18:09:52] Processing passage No. 7/10000\n",
      "2\n",
      "[Jul 16, 18:09:53] Processing passage No. 8/10000\n",
      "0\n",
      "[Jul 16, 18:09:54] Processing passage No. 9/10000\n",
      "2\n",
      "[Jul 16, 18:09:55] Processing passage No. 10/10000\n",
      "9\n",
      "[Jul 16, 18:09:56] Processing passage No. 11/10000\n",
      "0\n",
      "[Jul 16, 18:09:57] Processing passage No. 12/10000\n",
      "6\n",
      "[Jul 16, 18:09:58] Processing passage No. 13/10000\n",
      "1\n",
      "[Jul 16, 18:09:59] Processing passage No. 14/10000\n",
      "0\n",
      "[Jul 16, 18:10:00] Processing passage No. 15/10000\n",
      "8\n",
      "[Jul 16, 18:10:01] Processing passage No. 16/10000\n",
      "0\n",
      "[Jul 16, 18:10:03] Processing passage No. 17/10000\n",
      "19\n",
      "[Jul 16, 18:10:04] Processing passage No. 18/10000\n",
      "1\n",
      "[Jul 16, 18:10:05] Processing passage No. 19/10000\n",
      "15\n",
      "[Jul 16, 18:10:06] Processing passage No. 20/10000\n",
      "7\n",
      "[Jul 16, 18:10:07] Processing passage No. 21/10000\n",
      "4\n",
      "[Jul 16, 18:10:08] Processing passage No. 22/10000\n",
      "9\n",
      "[Jul 16, 18:10:09] Processing passage No. 23/10000\n",
      "0\n",
      "[Jul 16, 18:10:10] Processing passage No. 24/10000\n",
      "15\n",
      "[Jul 16, 18:10:11] Processing passage No. 25/10000\n",
      "1\n",
      "[Jul 16, 18:10:12] Processing passage No. 26/10000\n",
      "24\n",
      "[Jul 16, 18:10:13] Processing passage No. 27/10000\n",
      "17\n",
      "[Jul 16, 18:10:14] Processing passage No. 28/10000\n",
      "1\n",
      "[Jul 16, 18:10:15] Processing passage No. 29/10000\n",
      "1\n",
      "[Jul 16, 18:10:16] Processing passage No. 30/10000\n",
      "1\n",
      "[Jul 16, 18:10:17] Processing passage No. 31/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7cb336fb5248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mqid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_query_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mannoy_qid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         top_list = forward_passage_index.get_nns_by_vector(forward_ranker(generate_sparse(query_dict[qid]).to(DEVICE)).detach(),\n\u001b[0;32m---> 25\u001b[0;31m                                                    rank)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mis_matched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For each passage, use reverse_query_index to find top 1000 nearest queries\n",
    "# Use forward_passage_index to find top k passages for each of the query, count += 1 if the passage is in top k\n",
    "# Record the # of top k queries for each document \n",
    "# Plot histogram for distribution and compute the average\n",
    "random_test_passage = random.sample(test_passage_list, n_passage)\n",
    "# random_test_passage = random.sample(list(train_passage_list), n_passage)\n",
    "counter = 0\n",
    "rankings = []\n",
    "total_sum = 0\n",
    "match_count = 0\n",
    "non_zero = []\n",
    "forward_count = []\n",
    "for i, pid in enumerate(random_test_passage):\n",
    "    print_message(\"Processing passage No. \" + str(i+1) + \"/\" + str(n_passage))\n",
    "    embedding = reverse_ranker(forward_ranker(generate_sparse(passage_dict[pid]).to(DEVICE)).detach()).detach()\n",
    "    nearest_queries = reverse_query_index.get_nns_by_vector(embedding, n_query)\n",
    "    matching_list = []\n",
    "    temp_count = 0\n",
    "    if pid in list(train_passage_list):\n",
    "        forward_count.append(len(train_rank_dict[pid]))\n",
    "    \n",
    "    for i, annoy_qid in enumerate(nearest_queries):\n",
    "        qid = reverse_query_map[annoy_qid]\n",
    "        top_list = forward_passage_index.get_nns_by_vector(forward_ranker(generate_sparse(query_dict[qid]).to(DEVICE)).detach(),\n",
    "                                                   rank)\n",
    "        \n",
    "        is_matched = False\n",
    "        for j, annoy_pid in enumerate(top_list):\n",
    "            if forward_passage_map[annoy_pid] == pid:\n",
    "#                 print(\"Match!!!!! Rank: \" + str(j + 1))\n",
    "                matching_list.append(j + 1)\n",
    "                non_zero.append(j + 1)\n",
    "                is_matched = True\n",
    "                match_count += 1\n",
    "                temp_count += 1\n",
    "                break\n",
    "            if not is_matched:\n",
    "                matching_list.append(0)\n",
    "    print(temp_count)\n",
    "#     print(temp_count, len(train_rank_dict[pid]))\n",
    "    total_sum += sum(matching_list)\n",
    "    rankings.append(matching_list)\n",
    "    counter += 1\n",
    "print(match_count / n_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 85, 5, 79, 73, 2, 2, 19, 5, 4, 9, 9, 15, 18, 2, 14, 14, 33, 43, 34, 34, 21, 4, 31, 21, 21, 11, 14, 11, 24, 20, 51, 3, 20, 40, 56, 22, 42, 19, 73, 54, 58, 10, 41, 56, 56, 68, 43, 81, 63, 85, 25, 56, 62, 44, 25, 27, 82, 48, 32, 81, 81, 70, 70, 70, 83, 57, 4, 21, 41, 8, 72, 29, 20, 96, 96, 56, 80, 54, 34, 16, 21, 43, 11, 59, 9, 39, 44, 34, 48, 80, 15, 16, 9, 28, 26, 75, 1, 1, 78, 1, 16, 16, 37, 66, 6, 6, 31, 58, 27, 55, 94, 71, 70, 81, 30, 74, 65, 24, 19, 6, 34, 61, 61, 21, 43, 64, 77, 51, 69, 64, 69, 96, 3, 3, 72, 73, 96, 71, 60, 20, 87, 44, 61, 11, 92, 8, 96, 71, 47, 21, 68, 34, 18, 77, 97, 40, 79, 87, 78, 76, 99, 88, 51, 76, 63, 79, 48, 9, 91, 74, 33, 21, 68, 39, 85, 21, 54, 17, 71, 29, 86, 85, 16, 26, 100, 94, 32, 38, 82, 73, 71, 55, 8, 38, 38, 22, 14, 24, 16, 24, 52, 75, 24, 83, 100, 89, 45, 80, 40, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "non_zero_rankings = []\n",
    "for i in range(len(rankings)):\n",
    "    for j in rankings[i]:\n",
    "        if j != 0:\n",
    "            non_zero_rankings.append(j)\n",
    "print(non_zero_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.066666666666666"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_rankings) / len(rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
