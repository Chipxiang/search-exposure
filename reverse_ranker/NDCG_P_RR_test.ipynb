{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/jianx/search-exposure/')\n",
    "import torch\n",
    "from annoy import AnnoyIndex\n",
    "import forward_ranker.load_data as load_data\n",
    "import forward_ranker.train as train\n",
    "from forward_ranker.utils import print_message\n",
    "from forward_ranker.test import get_ndcg_precision_rr\n",
    "obj_reader = load_data.obj_reader\n",
    "obj_writer = load_data.obj_writer\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "GROUND_TRUTH_PATH = \"/datadrive/jianx/data/results/all_search_rankings_100_100_flat.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_ground_truth(path=GROUND_TRUTH_PATH):\n",
    "    all_results = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            qid = int(line.split(\",\")[0])\n",
    "            pid = int(line.split(\",\")[1])\n",
    "            rank = int(line.split(\",\")[2])\n",
    "            if pid not in all_results.keys():\n",
    "                all_results[pid] = {}\n",
    "            all_results[pid][qid] = 101 - rank\n",
    "    return all_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ratings = load_ground_truth(GROUND_TRUTH_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Full\n",
    "baseline_full = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/loss15_layer3/forward_baseline_rank_test.pickle\")\n",
    "append_full = obj_reader(\"/datadrive/ruohan/reverse_ranker/append/layer3_no_split/pred_rank_test.pickle\")\n",
    "residual_full = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/loss15_layer3/pred_rank_test.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Half\n",
    "baseline_half = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/train_query_250000/forward_baseline_rank_test.pickle\")\n",
    "append_half = obj_reader(\"/datadrive/ruohan/reverse_ranker/append/train_query_250000/pred_rank_test.pickle\")\n",
    "residual_half = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/train_query_250000/pred_rank_test.pickle\")\n",
    "\n",
    "# 1/10\n",
    "baseline_110 = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/train_query_50000/forward_baseline_rank_test.pickle\")\n",
    "append_110 = obj_reader(\"/datadrive/ruohan/reverse_ranker/append/train_query_50000/pred_rank_test.pickle\")\n",
    "residual_110 = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/train_query_50000/pred_rank_test.pickle\")\n",
    "\n",
    "# 1/10 sample from query\n",
    "baseline_q = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/train_query_50000_morepos/forward_baseline_rank_test.pickle\")\n",
    "append_q = obj_reader(\"/datadrive/ruohan/reverse_ranker/append/train_query_50000_morepos/pred_rank_test.pickle\")\n",
    "residual_q = obj_reader(\"/datadrive/ruohan/reverse_ranker/residual/train_query_50000_morepos/pred_rank_test.pickle\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_reverse_ndcg_precision_rr(true_dict, test_dict, rank):\n",
    "    sorted_result = list(test_dict.items())\n",
    "    original_rank = rank\n",
    "    rank = min(rank, len(sorted_result))\n",
    "    cumulative_gain = 0\n",
    "    num_positive = 0\n",
    "    rr = float(\"NaN\")\n",
    "    for i in range(len(sorted_result)):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        if pid in true_dict:\n",
    "            num_positive += 1\n",
    "    for i in range(rank):\n",
    "        pid = sorted_result[i][0]\n",
    "        relevance = 0\n",
    "        if pid in true_dict:\n",
    "            relevance = true_dict[pid]\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        cumulative_gain += discounted_gain\n",
    "    sorted_ideal = sorted(true_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ideal_gain = 0\n",
    "    for i in range(rank):\n",
    "        relevance = 0\n",
    "        if i < len(sorted_ideal):\n",
    "            relevance = sorted_ideal[i][1]\n",
    "        discounted_gain = relevance / math.log2(2 + i)\n",
    "        ideal_gain += discounted_gain\n",
    "    ndcg = 0\n",
    "    if ideal_gain != 0:\n",
    "         ndcg = cumulative_gain / ideal_gain\n",
    "    return ndcg, num_positive / original_rank, rr\n",
    "\n",
    "def calculate_metrics(rating_dict, result_dict, rank=10):\n",
    "    pids = list(result_dict.keys())\n",
    "    result_ndcg = []\n",
    "    result_prec = []\n",
    "    result_rr = []\n",
    "    for pid in pids:\n",
    "        if pid in rating_dict:\n",
    "            ndcg, prec, rr = get_reverse_ndcg_precision_rr(rating_dict[pid], result_dict[pid], rank)\n",
    "            result_ndcg.append(ndcg)\n",
    "            result_prec.append(prec)\n",
    "            result_rr.append(rr)\n",
    "    avg_ndcg = np.nanmean(result_ndcg)\n",
    "    avg_prec = np.nanmean(result_prec)\n",
    "    avg_rr = np.nanmean(result_rr)\n",
    "    print(\"NDCG@{}: {:.4f}\".format(rank,avg_ndcg),\"Precision@{}: {:.4f}\".format(rank, avg_prec), \"RR: {:.4f}\".format(avg_rr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With full query log\n",
      "Baseline forward embedding model\n",
      "NDCG@10: 0.6218 Precision@10: 0.3244 RR: 0.7892\n",
      "NDCG@100: 0.6915 Precision@100: 0.0605 RR: 0.7892\n",
      "Append embedding model\n",
      "NDCG@10: 0.8110 Precision@10: 0.4149 RR: 0.9073\n",
      "NDCG@100: 0.8533 Precision@100: 0.0693 RR: 0.9073\n",
      "Residual embedding model\n",
      "NDCG@10: 0.8204 Precision@10: 0.4183 RR: 0.9096\n",
      "NDCG@100: 0.8597 Precision@100: 0.0694 RR: 0.9096\n"
     ]
    }
   ],
   "source": [
    "print(\"With full query log\")\n",
    "print(\"Baseline forward embedding model\")\n",
    "calculate_metrics(ratings, baseline_full)\n",
    "calculate_metrics(ratings, baseline_full, 100)\n",
    "print(\"Append embedding model\")\n",
    "calculate_metrics(ratings, append_full)\n",
    "calculate_metrics(ratings, append_full, 100)\n",
    "print(\"Residual embedding model\")\n",
    "calculate_metrics(ratings, residual_full)\n",
    "calculate_metrics(ratings, residual_full, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With half query log\n",
      "Baseline forward embedding model\n",
      "NDCG@10: 0.6242 Precision@10: 0.3243 RR: 0.7910\n",
      "NDCG@100: 0.6945 Precision@100: 0.0606 RR: 0.7910\n",
      "Append embedding model\n",
      "NDCG@10: 0.8018 Precision@10: 0.4104 RR: 0.9015\n",
      "NDCG@100: 0.8462 Precision@100: 0.0689 RR: 0.9015\n",
      "Residual embedding model\n",
      "NDCG@10: 0.7732 Precision@10: 0.3964 RR: 0.8780\n",
      "NDCG@100: 0.8228 Precision@100: 0.0681 RR: 0.8780\n"
     ]
    }
   ],
   "source": [
    "print(\"With half query log\")\n",
    "print(\"Baseline forward embedding model\")\n",
    "calculate_metrics(ratings, baseline_half)\n",
    "calculate_metrics(ratings, baseline_half, 100)\n",
    "print(\"Append embedding model\")\n",
    "calculate_metrics(ratings, append_half)\n",
    "calculate_metrics(ratings, append_half, 100)\n",
    "print(\"Residual embedding model\")\n",
    "calculate_metrics(ratings, residual_half)\n",
    "calculate_metrics(ratings, residual_half, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1/10 query log\n",
      "Baseline forward embedding model\n",
      "NDCG@10: 0.6210 Precision@10: 0.3256 RR: 0.7913\n",
      "NDCG@100: 0.6912 Precision@100: 0.0609 RR: 0.7913\n",
      "Append embedding model\n",
      "NDCG@10: 0.6991 Precision@10: 0.3680 RR: 0.8201\n",
      "NDCG@100: 0.7634 Precision@100: 0.0672 RR: 0.8201\n",
      "Residual embedding model\n",
      "NDCG@10: 0.6936 Precision@10: 0.3603 RR: 0.8293\n",
      "NDCG@100: 0.7593 Precision@100: 0.0657 RR: 0.8293\n"
     ]
    }
   ],
   "source": [
    "print(\"With 1/10 query log\")\n",
    "print(\"Baseline forward embedding model\")\n",
    "calculate_metrics(ratings, baseline_110)\n",
    "calculate_metrics(ratings, baseline_110, 100)\n",
    "print(\"Append embedding model\")\n",
    "calculate_metrics(ratings, append_110)\n",
    "calculate_metrics(ratings, append_110, 100)\n",
    "print(\"Residual embedding model\")\n",
    "calculate_metrics(ratings, residual_110)\n",
    "calculate_metrics(ratings, residual_110, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from query results\n",
      "Baseline forward embedding model\n",
      "NDCG@10: 0.6223 Precision@10: 0.3219 RR: 0.7903\n",
      "NDCG@100: 0.6915 Precision@100: 0.0590 RR: 0.7903\n",
      "Append embedding model\n",
      "NDCG@10: 0.7656 Precision@10: 0.3923 RR: 0.8743\n",
      "NDCG@100: 0.8169 Precision@100: 0.0665 RR: 0.8743\n",
      "Residual embedding model\n",
      "NDCG@10: 0.7236 Precision@10: 0.3710 RR: 0.8471\n",
      "NDCG@100: 0.7831 Precision@100: 0.0650 RR: 0.8471\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample from query results\")\n",
    "print(\"Baseline forward embedding model\")\n",
    "calculate_metrics(ratings, baseline_q)\n",
    "calculate_metrics(ratings, baseline_q, 100)\n",
    "print(\"Append embedding model\")\n",
    "calculate_metrics(ratings, append_q)\n",
    "calculate_metrics(ratings, append_q, 100)\n",
    "print(\"Residual embedding model\")\n",
    "calculate_metrics(ratings, residual_q)\n",
    "calculate_metrics(ratings, residual_q, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Residual baseline forward embedding model\")\n",
    "calculate_metrics(ratings, baseline_reverse_residual)\n",
    "calculate_metrics(ratings, baseline_reverse_residual, 100)\n",
    "print(\"Residual embedding model\")\n",
    "calculate_metrics(ratings, trained_reverse_residual)\n",
    "calculate_metrics(ratings, trained_reverse_residual, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calculate_metrics(ratings, new_baseline_reverse)\n",
    "calculate_metrics(ratings, new_baseline_reverse,100)\n",
    "\n",
    "calculate_metrics(ratings, new_trained_reverse)\n",
    "calculate_metrics(ratings, new_trained_reverse, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5 6\n",
      "2 3 4\n",
      "1 1 2\n",
      "1 3 4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_results = {1:[(1,2),(3,4)],2:[(5,6),(3,4)],3:[(7,8),(3,4)]}\n",
    "train_set = dict(random.sample(list(train_results.items()), 2))\n",
    "for key,value in train_set.items():\n",
    "    for qid,rank in value:\n",
    "        print(key,qid,rank)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 08, 23:19:04] Loading embeddings.\n"
     ]
    }
   ],
   "source": [
    "print_message(\"Loading embeddings.\")\n",
    "passage_embeddings = obj_reader(\"/home/jianx/results/passage_0__emb_p__data_obj_0.pb\")\n",
    "query_train_embeddings = obj_reader(\"/home/jianx/results/query_0__emb_p__data_obj_0.pb\")\n",
    "query_train_mapping = obj_reader(\"/datadrive/jianx/data/annoy/100_ance_query_train_map.dict\")\n",
    "pid_mapping = obj_reader(\"/datadrive/jianx/data/annoy/100_ance_passage_map.dict\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[694.0746 , 692.02124, 691.7162 , 690.04065, 689.5751 , 688.8958 ,\n         688.7236 , 688.52374, 688.50146, 688.38464, 688.3286 , 687.8984 ,\n         687.7049 , 687.64087, 687.5666 , 687.0526 , 686.83325, 686.5188 ,\n         686.1091 , 685.68335, 685.2858 , 684.66833, 684.6572 , 684.63184,\n         684.4979 , 684.372  , 684.3336 , 684.2833 , 684.04095, 683.85657,\n         683.85455, 683.2638 , 682.99414, 682.90594, 682.9051 , 682.73004,\n         682.64417, 682.41626, 682.27124, 682.2625 , 681.9237 , 681.91614,\n         681.91187, 681.80334, 681.4107 , 681.4092 , 681.36536, 681.33496,\n         681.1986 , 680.83124, 680.7844 , 680.31506, 680.0169 , 680.0029 ,\n         679.9907 , 679.9363 , 679.67365, 679.55884, 679.55743, 679.30554,\n         679.23157, 679.1638 , 679.0986 , 679.08167, 678.9065 , 678.8589 ,\n         678.84595, 678.84375, 678.81696, 678.7909 , 678.62354, 678.2627 ,\n         677.9946 , 677.9926 , 677.82153, 677.6101 , 677.40936, 677.3904 ,\n         677.2928 , 677.0931 , 676.9078 , 676.8546 , 676.7677 , 676.7236 ,\n         676.44934, 676.2641 , 676.0559 , 675.7293 , 675.5866 , 675.52374,\n         675.5138 , 675.3094 , 674.4323 , 674.43036, 674.10486, 673.93097,\n         673.60944, 673.36694, 671.79834, 668.38074]], dtype=float32),\n array([[91, 96, 54, 16, 41, 76, 45, 73, 71, 65, 30, 47,  5,  4, 43, 23,\n         75,  8, 93,  9, 12, 11, 26,  0,  1, 79, 95, 49,  2, 74, 13, 25,\n          3, 57, 40, 98, 94, 86, 55, 19, 34, 78, 87, 61, 24, 39, 90, 52,\n         82, 14, 33, 60, 85, 99, 88,  7, 58, 46, 18, 44, 38, 62, 32, 22,\n         15, 37, 64, 48, 83, 80, 69, 97, 29, 84, 92, 72, 17, 89, 20, 81,\n         56, 68, 70, 31, 50, 42,  6, 67, 28, 35, 10, 53, 59, 66, 27, 36,\n         51, 63, 77, 21]]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "faiss.omp_set_num_threads(16)\n",
    "dim = passage_embeddings.shape[1]\n",
    "cpu_index = faiss.IndexFlatIP(dim)\n",
    "cpu_index.add(passage_embeddings[:100])\n",
    "cpu_index.search(np.array([query_train_embeddings[1]]), 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-py37_pytorch-py",
   "language": "python",
   "display_name": "Python [conda env:py37_pytorch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}